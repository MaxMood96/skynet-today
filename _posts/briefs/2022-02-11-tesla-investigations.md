---
layout: post
image:
  feature: assets/img/briefs/tesla-investigations/main.jpg
  credit: <a href="https://www.forbes.com/sites/bradtempleton/2020/06/02/tesla-in-taiwan-crashes-directly-into-overturned-truck-ignores-pedestrian-with-autopilot-on/?sh=1939367558e5">Laguna Beach Police Department via Forbes</a>
title: "Crashes caused by Tesla Autopilot are piling up, and there are consequences"
excerpt: "Will current investigations make automated driving systems safer or slow down the dream of self-driving cars?"
author: [trisha_mittal]
tags: [Elon Musk, self-driving]
categories: [briefs]
permalink: /briefs/tesla-investigations
sidebartoc: true
highlight: false
---

## Summary

* Tesla’s advanced driving assistance system, AutoPilot, is under multiple investigations over recent crashes. 
* Moreover, the US recorded its first ever charging of an individual involved in a fatal crash while engaged with a driving assistance system. 
* Across academia, industry, and the press, many stress the need for these investigations and how Tesla's claims about the Autopilot system are overhyped. 
* While it is important to investigate these cases, their findings should be used to improve autonomous driving instead of hampering future development of self-driving cars. 

## What Happened

For the first time in history, the [US has charged an individual involved in a fatal crash](https://www.latimes.com/california/story/2022-01-18/felony-charges-are-first-in-fatal-crash-involving-teslas-autopilot) when engaging with a partially automated driving assistance system. 
The driver of the Tesla was charged for killing two people because of the fatal crash that happened almost 2 years ago in Los Angeles.

<blockquote class="twitter-tweet tw-align-center"><p lang="en" dir="ltr">Nearly 2 years later, prosecutors in L.A. County filed 2 counts of vehicular manslaughter against the Tesla driver. Experts believe it is the 1st felony prosecution in the U.S. of a driver accused of causing a fatality while using a driver-assist system.<a href="https://t.co/xp4FnigShR">https://t.co/xp4FnigShR</a></p>&mdash; Los Angeles Times (@latimes) <a href="https://twitter.com/latimes/status/1483861183044075523?ref_src=twsrc%5Etfw">January 19, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

The crash happened like this: the Tesla was moving at a high speed, left a freeway, ran a red light, and struck a Honda Civic at an intersection. 
Two people in the Honda Civic died at the scene, and the two passengers in the Tesla suffered non-life-threatening injuries. 
While the investigation does not mention anything about Autopilot, the NHTSA later confirmed that the Autopilot was engaged in the Tesla during the time leading to the crash. 

This news does not completely come as a shock considering the [ongoing investigation](https://static.nhtsa.gov/odi/inv/2021/INOA-PE21020-1893.PDF) by the National Highway Traffic Safety Administration (NHTSA) into Tesla’s Autopilot system following 12 crashes that have left 17 people injured and one dead since 2014. 
According to the [documents filed](https://static.nhtsa.gov/odi/inv/2021/INOA-PE21020-1893.PDF) for the already ongoing investigation into Tesla’s Autopilot, the inquiry is focused on 765,000 Teslas — models Y, X, S and 3 — produced from 2014 to 2021.

We combed through all 12 crashes and summarized them in the table below. 
Each row is a crash, and the link on the date points to a news article on that incident.

|Date|Place|Time|Vehicle Hit or Ran Into|Flashing Lights|Bright Objects|
|:----: |:----:  |:----: |:----:  |:----: |:----: |:----: |
|[01/22/2018](https://www.siliconvalley.com/2018/01/22/tesla-on-autopilot-slams-into-parked-fire-truck-on-freeway)|Culver City, CA|11AM|Parked Fire truck|Y|-|
|[05/20/2018](https://www.latimes.com/local/lanow/la-me-ln-tesla-collision-20180529-story.html)|Laguna Beach, CA|11AM|Police SUV|Y|-|
|[12/07/2019](https://www.ctinsider.com/news/article/Norwalk-crash-in-2019-one-of-11-that-prompted-16394014.php)|Norwalk, CT|4AM|Parked Cruiser + Disabled car (Chain Collision)|Y|Flares|
|[12/29/2019](https://www.bannergraphic.com/story/2856765.html)|Cloverdale, IN|8AM|Parked Fire truck (earlier crash scene)|Y|-|
|[01/22/2020](https://www.nbcboston.com/investigations/federal-government-investigating-tesla-crash-in-massachusetts/2229521/)|West Bridgewater, MA|10PM|State Trooper SUV + Car (Chain Collision)|Y|Illuminated Arrow Board|
|[07/30/2020](https://www.azcentral.com/story/news/local/arizona-breaking/2020/07/14/tesla-autopilot-hits-dps-patrol-car-10-near-benson/5439368002)|Cochise County, AZ|4AM|Highway Patrol + Ambulance (Chain Collision)|Y|-|
|[08/26/2020](https://www.wcnc.com/article/news/weird/tesla-crashes-north-carolina-deputies-nash-county-autopilot/275-acb0e707-0b20-450c-84f0-25442d781eba)|Spring Hope, NC|12AM|Deputy’s Cruiser + State Trooper Vehicle (Chain Collision)|Y|-|
|[02/27/2021](https://abc13.com/police-car-crash-constable-montgomery-county-deputy-injured/10375181)|Montgomery County, TX|1AM|Highway Patrol Car|Y|-|
|[03/17/2021](https://www.freep.com/story/news/local/michigan/2021/03/17/tesla-autopilot-crash-michigan-state-police-patrol-car/4731376001)|Lansing, MI|1AM|State Trooper Vehicle|Y|-|
|[05/19/2021](https://www.local10.com/news/local/2021/05/19/3-injured-after-tesla-collides-with-road-ranger-truck-on-i-95/)|Miami, FL|5AM|Florida Department of Transport Truck|Y|Cones|
|[07/10/2021](https://www.nbcsandiego.com/news/local/tesla-crash-with-chp-vehicle-in-san-diego-part-of-investigation-into-autopilot-feature/2694531)|San Diego, CA|3AM|California Highway Patrol Cruiser|Y|-|
|[08/28/2021](https://www.clickorlando.com/news/local/2021/08/30/tesla-driver-claims-autopilot-was-on-when-she-crashed-into-patrol-car-but-we-may-never-know/)|Orlando, FL|5AM|Florida Highway Patrol Vehicle|Y|Cones|

"-" means no information found 

Al the 12 crashes being investigated involved one or more emergency vehicles parked on highway lanes either attending to a previous crash scene or conducting regular monitoring operations. All had their emergency lights flashing at the time of the crash. 
Most of the crashes (nine of the twelve) also occurred in late night or early morning with dark lighting conditions. 
Some incidents also report additional emergency and closure signs like flares, road cones and illuminated arrow boards at the time of the crash. 
We refer readers to [this link](https://www.mercurynews.com/2021/09/07/list-the-12-tesla-accidents-that-are-being-investigated-by-the-nhtsa/) for a more detailed reading about the 12 attacks. 
Below are some tweets concerning these accidents: 

<blockquote class="twitter-tweet tw-align-center"><p lang="en" dir="ltr">This morning a Tesla sedan driving outbound Laguna Canyon Road in “autopilot” collides with a parked @LagunaBeachPD unit. Officer was not in the unit at the time of the crash and minor injuries were sustained to the Tesla driver. <a href="https://twitter.com/hashtag/lagunabeach?src=hash&amp;ref_src=twsrc%5Etfw">#lagunabeach</a> <a href="https://twitter.com/hashtag/police?src=hash&amp;ref_src=twsrc%5Etfw">#police</a> <a href="https://twitter.com/hashtag/tesla?src=hash&amp;ref_src=twsrc%5Etfw">#tesla</a> <a href="https://t.co/7sAs8VgVQ3">pic.twitter.com/7sAs8VgVQ3</a></p>&mdash; Laguna Beach PD PIO (@LBPD_PIO_45) <a href="https://twitter.com/LBPD_PIO_45/status/1001541486146547717?ref_src=twsrc%5Etfw">May 29, 2018</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet tw-align-center"><p lang="en" dir="ltr">A Weston man driving a Tesla slammed into a Mass. State Police cruiser that was stopped <a href="https://t.co/kjAbaQabsG">https://t.co/kjAbaQabsG</a></p>&mdash; NBC10 Boston (@NBC10Boston) <a href="https://twitter.com/NBC10Boston/status/1277937457569423363?ref_src=twsrc%5Etfw">June 30, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet tw-align-center"><p lang="en" dir="ltr">While working a freeway accident this morning, Engine 42 was struck by a <a href="https://twitter.com/hashtag/Tesla?src=hash&amp;ref_src=twsrc%5Etfw">#Tesla</a> traveling at 65 mph. The driver reports the vehicle was on autopilot. Amazingly there were no injuries! Please stay alert while driving! <a href="https://twitter.com/hashtag/abc7eyewitness?src=hash&amp;ref_src=twsrc%5Etfw">#abc7eyewitness</a> <a href="https://twitter.com/hashtag/ktla?src=hash&amp;ref_src=twsrc%5Etfw">#ktla</a> <a href="https://twitter.com/hashtag/CulverCity?src=hash&amp;ref_src=twsrc%5Etfw">#CulverCity</a> <a href="https://twitter.com/hashtag/distracteddriving?src=hash&amp;ref_src=twsrc%5Etfw">#distracteddriving</a> <a href="https://t.co/RgEmd43tNe">pic.twitter.com/RgEmd43tNe</a></p>&mdash; Culver City Firefighters (@CC_Firefighters) <a href="https://twitter.com/CC_Firefighters/status/955529991319560192?ref_src=twsrc%5Etfw">January 22, 2018</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet tw-align-center"><p lang="en" dir="ltr">No injuries to troopers or anyone involved. Driver of the Tesla, a 22 year old man from Lansing was issued citations for failure to move over and DWLS. <a href="https://t.co/zTSJOhuJMP">pic.twitter.com/zTSJOhuJMP</a></p>&mdash; MSP First District (@MSPFirstDist) <a href="https://twitter.com/MSPFirstDist/status/1372152867612733441?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

## The Reactions

To better understand the reactions of the various press outlets and experts to these crashes, it is important to understand what Autopilot actually does. 
Tesla’s Autopilot system has two main features: Traffic-Aware Cruise Control and Autosteer. 
The former helps the car accelerate/decelerate and maintain speed, while the latter helps the car stay in lane using data-driven learning algorithms. 
This is still considered level 2 autonomy, also called partial automated driving assistance. 
We refer the readers to [The 6 Levels of Autonomy Explained](https://www.synopsys.com/automotive/autonomous-driving-levels.html) to understand the various levels of autonomy. 
More details regarding Tesla’s Autopilot system can be found in the blog post, [Tesla's Autopilot Explained!](https://www.louisbouchard.ai/tesla-autopilot-explained-tesla-ai-day/) 
According to Tesla’s guidelines, when the Autopilot is engaged, it does not make the vehicle safe to operate without a human driver behind the wheel.

### From the Press

There has been a lot of coverage regarding Teslas investigations with headlines like:

* Engineering and Technology Magazine: [Tesla called on to explain Autopilot function](https://eandt.theiet.org/content/articles/2021/09/tesla-called-on-to-explain-autopilot-function/)
* Forbes: [What Will Come Out Of NHTSA's Tesla Autopilot Investigation](https://www.forbes.com/sites/samabuelsamid/2021/08/23/what-will-come-out-of-nhtsas-tesla-autopilot-investigation/)?
* The Washington Post: [Tesla Autopilot faces U.S. safety regulator’s scrutiny after crashes with emergency vehicles](https://www.washingtonpost.com/business/2021/08/16/tesla-autopilot-investigation-nhtsa/)
* The New York Times: [Tesla is ordered to turn over Autopilot data to a federal safety agency](https://www.nytimes.com/2021/09/01/business/tesla-autopilot-investigation.html)
* TechCrunch: [US safety regulator opens investigation into Tesla Autopilot following crashes with parked emergency vehicles](https://techcrunch.com/2021/08/16/u-s-safety-regulator-opens-investigation-into-tesla-autopilot-following-crashes-with-parked-emergency-vehicles/)
* Reuters: [U.S. opens probe into Tesla’s Autopilot over emergency vehicle crashes](https://www.reuters.com/business/autos-transportation/us-opens-formal-safety-probe-into-tesla-autopilot-crashes-2021-08-16/)

All these articles explain the intensity of many of these crashes and the extent of data requested by NHTSA from Tesla regarding the capabilities of the Autopilot system. 
More specifically, regarding the first ever charge because of Autopilot, many coverages have also raised questions and explain why self-driving cars are still far from reality:

* The Conversation: [‘Self-driving’ cars are still a long way off. Here are three reasons why](https://theconversation.com/self-driving-cars-are-still-a-long-way-off-here-are-three-reasons-why-159234)
* MarketWatch: [You will not be traveling in a self-driving car anytime soon. Here’s what the future will look like](https://www.marketwatch.com/story/you-will-not-be-traveling-in-a-self-driving-car-anytime-soon-heres-what-the-future-will-look-like-11623866219)
* Insider: [Experts say we're decades from fully autonomous cars. Here's why.](https://www.businessinsider.com/self-driving-cars-fully-autonomous-vehicles-future-prediction-timeline-2019-8)
* Seattle Times: [Despite promises, totally self-driving cars still in the future](https://www.seattletimes.com/business/technology/where-are-our-self-driving-cars/)

Meanwhile, Tesla’s marketing has also been a concern for a very long time. 
Tesla’s CEO has continued to make false and overinflated claims regarding Autopilot’s capabilities. 
This is evident in these two tweets. 

<blockquote class="twitter-tweet tw-align-center"><p lang="en" dir="ltr">True. Anyone paying attention to the rate of improvement will realize that Tesla Autopilot/FSD is already superhuman for highway driving &amp; swiftly getting there for city streets.</p>&mdash; Elon Musk (@elonmusk) <a href="https://twitter.com/elonmusk/status/1387892143792984065?ref_src=twsrc%5Etfw">April 29, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet tw-align-center"><p lang="en" dir="ltr">Gating factor is achieving &amp; proving higher safety with pure vision than with vision+radar. We are almost there.<br><br>FSD Beta V9.0 will blow your mind.</p>&mdash; Elon Musk (@elonmusk) <a href="https://twitter.com/elonmusk/status/1387572858768007179?ref_src=twsrc%5Etfw">April 29, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

There is also a lot of discussion in the press regarding the hype and buzz created by Tesla:

* Bloomberg: [The Only Thing On Autopilot At Tesla Is The Hype Machine](https://www.bloomberg.com/opinion/articles/2016-10-21/the-only-thing-on-autopilot-at-tesla-is-the-hype-machine)
* Electrik: [Elon Musk hypes Tesla Full Self-Driving Beta driving visualizations with new update](https://electrek.co/2021/04/29/elon-musk-hypes-tesla-full-self-driving-beta-driving-visualization-new-update/)
* Scientific American: [‘Self-Driving’ Cars Begin to Emerge from a Cloud of Hype](https://electrek.co/2021/04/29/elon-musk-hypes-tesla-full-self-driving-beta-driving-visualization-new-update/)

### From the Experts

Prof. Phil Koopman, at Carnegie Mellon University, noting that NHTSA has requested information about Tesla’s entire Autopilot-equipped fleet, [says](https://www.cnbc.com/2021/09/01/tesla-must-deliver-autopilot-crash-data-to-nhtsa-by-october-22.html):

> This is an incredibly detailed request for huge amounts of data. But it is exactly the type of information that would be needed to dig into whether Tesla vehicles are acceptably safe.

Sam Abuelsamid, an expert in self-driving vehicles and principal analyst at Guidehouse Insights writes about self-driving cars frequently. 
He said that while partial automated driving systems can slow down cars when required, most vehicles are designed to ignore stationary objects when traveling at more than 40 mph, so they don’t slam on the brakes when approaching overpasses or stationary objects on the side of the roads, such as a car stopped on the shoulder. 
He also [comments](https://www.forbes.com/sites/samabuelsamid/2021/08/23/what-will-come-out-of-nhtsas-tesla-autopilot-investigation/?sh=2ed275ec6430):

> When it works, which can be most of the time, it can be very good. But it can easily be confused by things that humans would have no problem with. Machine visions are not as adaptive as humans. And the problem is that all machine systems sometimes make silly errors.

Gary Marcus, founder and CEO of Robust.AI has often voiced his concerns regarding the hype that Tesla creates regarding their Autopilot system. 

<blockquote class="twitter-tweet tw-align-center"><p lang="en" dir="ltr">“full safety driving”, my eye. this is what you get when you overhype your AI. <a href="https://t.co/C8oSajmyRt">https://t.co/C8oSajmyRt</a></p>&mdash; Gary Marcus (@GaryMarcus) <a href="https://twitter.com/GaryMarcus/status/1383850861432958977?ref_src=twsrc%5Etfw">April 18, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Tesla’s Autopilot heavily depends on sensors like cameras and AI algorithms to infer the car’s surroundings, like location and speeds of other vehicles, through these sensors. 
A large chunk of the autonomous driving community also heavily questionthat the self driving capabilities can be achieved solely with data-driven algorithms. 
Chris Ursman, head of self-driving startup Aurora, said that his company combines AI with other technologies to come up with systems that can apply general rules to novel situations, as a human would.
On the timeline for self-driving in the near future, he [notes](https://www.wsj.com/articles/self-driving-cars-could-be-decades-away-no-matter-what-elon-musk-said-11622865615):

> We’re going to see self-driving vehicles on the road doing useful things in the next couple of years, but for it to become ubiquitous will take time.

Melanie Mitchell, a computer scientist and professor of complexity at the Santa Fe Institute notes in her article, [Why AI is Harder Than We Think](https://dl.acm.org/doi/10.1145/3449639.3465421), that [AI alone is not sufficient for self-driving cars](https://www.wsj.com/articles/self-driving-cars-could-be-decades-away-no-matter-what-elon-musk-said-11622865615):

> Getting to autonomous vehicles the old-fashioned way, with tried-and-true systems engineering, would still mean spending huge sums outfitting our roads with transponders and sensors to guide and correct the robot cars. And they would remain limited to certain areas, and certain weather conditions—with human teleoperators on standby should things go wrong, she adds._

## Our Perspective

Autonomous driving has progressed significantly in the last decade, but the general consensus is that there is still a long road ahead to achieving a fully automated self-driving car that will not require any human driver behind the wheel. We refer readers to Rodney Brooks’s (CTO and co-founder of Robust.io) blog, [Predictions Scorecard, 2022 January 01](https://rodneybrooks.com/predictions-scorecard-2022-january-01/) where he makes annual predictions about self-driving cars. 

Regarding the current investigations into Tesla’s Autopilot system, we believe it is important that the investigation be thorough and can yield important and actionable insights, which, hopefully, can improve the current autonomous driving system. We hope that the following questions can be answered with these investigations:

* How does Autopilot detect emergency vehicles, flashing lights, road cones put in place for temporary road and traffic maintenance? 
* It was evident that most of these crashes happened in the dark. Has this apparent flaw been fixed in recent Autopilot updates?
* Going forward, can we anticipate and fix similar problems in self-driving systems?

It is inevitable in the near future that there will be many more driver-assist programs with varying levels of autonomy and features. 
For self-driving cars to co-exist with other human drivers on shared roads and conditions, it is important for regulatory bodies like NHTSA to come up with guidelines for evaluating and testing the upcoming self-driving systems. 
Moreover, these guidelines be made  with inputs from experts in industry and academia. 

Simultaneously, while these systems are in nascent stages, it is important to ensure that companies inform consumers of the limitations of the existing assisted driving programs. 
Customers should also be held accountable if they do not adhere to the company guidelines. 
We believe that if all the stakeholders, regulatory bodies, self-driving companies, experts in the area and the consumers can play their role, then these investigations will only help for the better. 

## Conclusion

Autonomous driving is one of the most anticipated technologies in this century. From academic institutions to industry labs, researchers to practitioners to executives are continuously improving perception, prediction, and planning capabilities of autonomous vehicles by testing their software in real-world environments. 
Despite the amount of progress made, there is still a lot of room for improvement, as the greatest challenge is to anticipate the [long tail](https://www.forbes.com/sites/lanceeliot/2021/07/13/whether-those-endless-edge-or-corner-cases-are-the-long-tail-doom-for-ai-self-driving-cars/) of real-world situations and react accordingly. 
Companies that work on autonomous driving should conduct more thorough testing and accurately inform consumers about the limitations of such systems. Otherwise, it will take a long time and many more accidents for self-driving cars to be considered acceptably safe.
