---
title: "AI news in 2021 (so far) with the Towards Data Science Podcast"
excerpt: "A discussion of some AI highlights from the first half of 2021"
image: 
  feature: assets/img/podcast/2021-07-21-tds-crossover/main.png
categories: [podcast]
tags: [interview]
permalink: /podcast/tds-crossover
---
<iframe title="Reflecting on AI news in 2021 (so far) with the host of the Towards Data Science Podcast" allowtransparency="true" style="border: none; min-width: min(100%, 430px);" scrolling="no" data-name="pb-iframe-player" src="https://www.podbean.com/player-v2/?i=q2vvz-1095531-pb&from=embed&share=1&download=1&skin=f6f6f6&btn-skin=3267a3&size=150" width="100%" height="150"></iframe>

 2021 has been a bit less crazy than 2020 so far, but plenty of notable stuff has already happened. So, we decided to partner with our friends over at the Towards Data Science podcast, hosted by co-founder of ShapestMinds Jeremie Harris.
Here were some of the major themes we discussed:

* Multi-modal learning. If 2020 was the year of large language models and meta-learning, 2021 so far has been the year of large, multi-modal models that combine vision and text together. OpenAI’s CLIP and DALL-E models have shown just how robust the combination of language modeling and vision can be. DALL-E in particular has shown itself to be capable of generating very impressive images based on user-specified text prompts. Presumably, there’s much more to come in this area, including integrations with robotics and a continued push toward bringing AI into the physical world.
* Bias in AI models. New questions are being raised about when and how AI should be applied, given established problems with bias in AI algorithms. Recently, a black man sued the New Jersey Police Department after spending 10 days in jail after allegedly being misidentified by a computer vision system as a shoplifter. Incidents such as this one have motivated renewed interest on the part of national and international regulators to address the challenges posed by AI systems. They also force us to think about what fairness and bias objectively are: only once we define these terms rigorously can they be technically tractable.
* Ownership rights in the era of generative AI. AI models were recently used to generate a series of fake — but eerily plausible — Nirvana songs, despite the death of their front man Kurt Cobain’s death in 1994. This leads to an interesting question: who owns the rights to this music? And who should? As AI systems make us think of creativity itself in new ways, they also force us to question assumptions we’ve made about credit assignment and copyright for centuries. It’s becoming clear that not understanding AI is no longer optional for many people — including lawyers, judges and politicians — who once could afford to outsource their thinking to specialists on these kinds of issues.

Subscribe: <a href="https://feed.podbean.com/aitalk/feed.xml">RSS</a> |
<a href="https://podcasts.apple.com/us/podcast/lets-talk-ai/id1502782720">iTunes</a> |
<a href="https://open.spotify.com/show/17HiNdxcoKJLLNibIAyUch">Spotify</a> |
<a href="https://pca.st/podcast/824c4060-472b-0138-9766-0acc26574db2">Pocket Casts</a> |
<a href="https://www.youtube.com/channel/UCKARTq-t5SPMzwtft8FWwnA">YouTube</a>

<div id="OU4horohTGe2lIV3fZiXKg"><script src="https://embed.trint.com/OU4horohTGe2lIV3fZiXKg/player.js"></script></div>
