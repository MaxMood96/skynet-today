---
title: "Skynet This Year 2018"
excerpt: "A roundup of notable AI news from 2018 that are still relevant today"
tags: [meta]
permalink: /digests/this-year-2018
toc: true
---

Ever since starting [this May](/digests/the-first), our Skynet This Week newsletter has been providing a digest of important AI news on a (roughly) bi-weekly basis. This edition collects the most noteworthy news from all 14 editions of Skynet This Week that are still relevant to be aware of today, and presents a little roundup of all the other writing we've put out this year. Big thanks to contributors Limor Gultchin, Alex Constantino, Viraat Aryabumi, Arnav Arora, and Lana Sinapayen for making this possible! And as always, feel free to <a href="https://goo.gl/forms/6e34w1B6vImi9wkZ2"><b>provide feedback</a></b>, <a href="https://goo.gl/forms/BUN03yZmpS0L2uMY2"><b>suggest coverage</a></b>, or <a href="https://goo.gl/forms/XVMpnbggACmHWfxW2"><b>express interest in helping</a></b>.

**Table of Contents**
* TOC
{:toc}

## Skynet Today This Year
Before we get into the news proper, the end of the year presents a good opportunity to highlight all the writing we have done to explain AI in more depth than we do with the digests. 

#### Briefs
The site was started with the primary intention of writing briefs on AI news - concise yet thorough articles that summarize and comment on an important recent AI story. This site publicly launched little more than 8 months ago, but we managed to finish 14 articles this year. Not bad! And here they all are for your browsing:

* [OpenAI's Not So Open DotA AI](/briefs/openai-dota-ii/) - An impressive demo by OpenAI leaves many questions unanswered
* [Deepfakes - Is Seeing Still Believing?](/briefs/deepfakes/) - Has widespread misuse of AI arrived? Not quite yet...
* [Can a \"Google AI\" Build Your Genome Sequence?](/briefs/google-deepvariant/) - A new AI-powered tool from Google promises more-accurate genome sequences, but its impact on genomics research remains to be seen
* [Is Data-Driven AI Brainwashing us all, or is it Just the Same as Good ol' Marketing?](/briefs/fb-cambridge-analytica/) - The many claims made as part of the recent Cambridge Analytica & Facebook scandal, reviewed
* [Tesla's Lethal Autopilot Crash — A Failing of UI as Much as AI](/briefs/tesla-crash/) - The tragedy might have been avoided if the limitations of the Autopilot were communicated more clearly
* [So What Was Up With Alexa's Creepy Laughter Anyway?](/briefs/alexa-laughter/) - A funny viral event talks to our ever increasing anxiety about AI and pervasive technology
* [Biased Facial Recognition - a Problem of Data and Diversity](/briefs/face-recog/) - Flashy headlines often hijack meaningful and important conversations on this topic, even when the articles are solid, as was the case here
* ['Do You Trust This Computer’ Gets a Whole Lot Wrong About AI Risks](/briefs/do-you-trust) - A Chris Paine documentary about AI promoted by Elon Musk conflates real AI risks with imaginary ones
* [Evil Software Du Jour: Google's Cocktail Party Algorithm](/briefs/google-speech-separation) - Recent privacy concerns over work from Google showcased how easy it is for media to immediately jump to unlikely worst-case outcomes
* [Google Translate's 'Sinister Religious Prophecies', Demystified](/briefs/google-nmt-prophecies) - Yet again, an unremarkable and well understood aspect of an AI system has been made out to be creepy and hard to explain
* [Amazon Rekognition Mistook Congressmen for Criminals? A Closer Look](/briefs/aclu-amazon-rekognition) - Examining ACLU’s claims of racial bias in face recognition technology as surveillance risk
* [Examining Henry Kissinger's Uninformed Comments on AI](/briefs/kissinger-ai) - Another public figure with no expertise on AI issues sweeping, unfounded statements about it threatening humanity
* [Google's LYmph Node Assistant - a Boost, not Replacement, for Doctors](/briefs/lyna) - A new tool from Google promises 99 percent accuracy in identifying cancer in lymph nodes - but it's too early to claim it surpasses humans
* [Sophia the Robot, More Marketing Machine Than AI Marvel](/briefs/sophia) - First robot to be granted a citizenship and a visa, Sophia does not have much to offer in terms of technology

Big thanks to authors Joshua Morton, Alex Constantino, Ben Shih, Viraat Aryabumi, Limor Gultchin, Lana Sinapayen, Aidan Rocke, Julia Gong, and Sneha Jha! 

#### Editorials
But, not all topics fit into the short format of a digest, and that's why we have editorials - longer and more in-depth pieces that are more opinionated and less news-specific. And here too, we did pretty well with 12 articles. And here they all are:

* [Why Skynet Today](/editorials/why-skynet-today) - We are working on the Snopes for AI — here is why
* [AlphaGo Zero Is Not A Sign of Imminent Human-Level AI](/editorials/is-alphago-zero-overrated) - Why DeepMind's Go playing program is not about to solve all of AI
* [Call for Collaborators and Submissions](/editorials/call-for-collaborators) - Know about AI and agree with this site's mission? Contribute!
* [Skynet Yesterday, Today and Tomorrow](/editorials/yesterday-today-tomorrow) - The evolution of discussions about AI has never been as fast paced as it is now, and so we too have been up to a lot lately
* [Artificial Intelligence: Think Again](/editorials/ai-think-again) - AI has a public relations problem, and AI researchers should do something about it
* [Autonomous Driving, Both Close and Far from Ubiquity](/editorials/autonomous_vehicles) - Autonomous vehicle technology has made huge advances in the last couple of years — what's left to solve? A whole lot.
* [Has AI surpassed humans at translation? Not even close!](/editorials/state_of_nmt) - Neural network translation systems still have many significant issues which make them far from superior to human translators
* [Inside an AI Conference - Robotics Science and Systems](/editorials/inside-ai-conference-rss) - What do AI researchers do at conferences? Check this out to find out!
* [Why We Find Self-Driving Cars So Scary](/editorials/why-self-driving-scary) - Even if autonomous cars are safer overall, the public will accept the new technology only when it fails in predictable and reasonable ways
* [The singularity isn’t here yet. Biased AI is.](/editorials/biased-ai) - A summary of what AI bias is, why we should care, and what we can and are doing about it
* [Symbiotic human-level AI: fear not, for I am your creation](/editorials/symbiotic-ai) - Human-level AI may well be possible — and we may not have to fear it
* [Why Your AI Might Be Racist](/editorials/why-your-ai-might-be-racist) - On the risks of enshrining all sorts of injustices into computer programs, where they could fester undetected in perpetuity.

Big thanks to contributors Jerry Kaplan, Olaf Witkowski, Sharon Zhou, Limor Gultchin, Apoorva Dornadula, and Henry Mei!

## Advances & Business

#### [Boston Dynamics is going to start selling its creepy robots in 2019](https://qz.com/1276281/softbanks-boston-dynamics-will-start-selling-its-spotmini-robots-in-2019/)
**Quartz** | from the [May 14th edition](/digests/the-first)

Apparently, "The robot apocalypse has been tentatively scheduled for late 2019". The robots in focus are products of Boston Dynamics, now a SoftBank company, which . Where to start? Perhaps at the start - that first sentence is obviously hyperbolic, and though it may be in jest given the amount of anxiety about AI and robotics that may not be the best tact to take. Towards the end of the piece the author speculates ‘It’s easy to see how a robot like this could be used in office security, or trained to hunt and kill us. (Oh wait, that was Black Mirror.)’ It’s easy to see why this piece earned itself a place in our downright silly section; the gap between a robot dog with 90 minutes of battery life and Terminator-esque apocalypse is, well, significant.

#### [A team of AI algorithms just crushed humans in a complex computer game](https://www.technologyreview.com/s/611536/a-team-of-ai-algorithms-just-crushed-expert-humans-in-a-complex-computer-game/) 
**Will Knight, MIT Tech Review** | from the [July 16th edition](/digests/the-fourth)

OpenAI has followed up on its 2017 achievement of beating pros at a 1v1 variation of the popular strategy game DoTA with a far more impressive feat: [managing to beat a team of human players at a much more complex 5v5 variation of the game](https://blog.openai.com/openai-five/). Interestingly, the achievement was reached without any algorithmic advances, as OpenAI explain:

> “OpenAI Five plays 180 years worth of games against itself every day, learning via self-play. It trains using a scaled-up version of Proximal Policy Optimization running on 256 GPUs and 128,000 CPU cores ... This indicates that reinforcement learning can yield long-term planning with large but achievable scale — without fundamental advances, contrary to our own expectations upon starting the project.”

Though definitely impressive, it should be remembered that these systems took hundreds of human lifetimes to train just to play one game. So, just as with prior achievements in Go, they represent the success of present day AI at mastering single narrow skills using a ton of computation, and not the ability to match humans at learning many skills with much less experience.

####  [AI bots are getting better than elite gamers](https://theoutline.com/post/5746/ai-bots-are-getting-better-than-elite-gamers)
**Oscar Schwartz, The Outline** | from the [August 13th edition](/digests/the-sixth)

The Outline has an accessible piece on Open AI’s Dota victories. It does a great job positioning the achievement relative to others like IBM’s Watson and DeepMind’s AlphaGo.

####  [Artificial intelligence and the rise of the robots in China](http://www.atimes.com/article/artificial-intelligence-and-the-rise-of-the-robots-in-china/)
**Gordon Watts, Asia Times** | from the [August 13th edition](/digests/the-sixth)

Asia Times has a fascinating article about the adoption of robots in China, including a robotic teaching assistant for preschools and a package delivery robot. This complements a recent [piece](https://www.nytimes.com/2018/07/21/technology/china-future-robot-waiters.html) by the New York Times showing that China may be diving head first into consumer robotics.

####  [The poet in the machine: Auto-generation of poetry directly from images through multi-adversarial training – and a little inspiration](https://www.microsoft.com/en-us/research/blog/the-poet-in-the-machine-auto-generation-of-poetry-directly-from-images-through-multi-adversarial-training-and-a-little-inspiration/)
**Microsoft Research Blog** | from [November 5th edition](/digests/the-twelfth)

>The point of this research is not to have AI replace poets. It’s about the myriad applications that can augment creative activity and achievement that the existence of even mildly creative AI could represent. Although the researchers acknowledge achieving truly creative AI is yet very far away, the boldness of their project and the encouraging results have been inspiring.

A team of researchers at Microsoft Research Asia attempted to train a research model that generates poems from images directly using an end to end approach. The task of generating accurate captions from images is still an “unsolved” NLP problem but the researchers attempted to do something even harder to pave way for future research in this domain. In the process, the researchers also managed to assemble two poem datasets using living annotators. 

####  [Germany plans 3 billion in AI investment: government paper](https://www.reuters.com/article/us-germany-intelligence/german-government-has-set-aside-around-3-billion-euros-for-artificial-intelligence-report-idUSKCN1NI1AP)
**Holger Hansen, Reuters** | from [November 19th edition](/digests/the-thirteenth)

Germany is planning to invest 3 billion euros in AI R&D until 2025, as outlined in an new “AI made in Germany” strategy paper. Governments around the world are paying more attention to the development of AI, noting its broad applications in many sectors across industry, healthcare, and the military. While the U.S. has yet to draft a national AI strategy, China released its own in 2017 and so did France in early 2018. An AI strategy is especially urgent for Germany as its car industry, an important engine for German economic growth, is falling behind in the development of self-driving (and electric) vehicles to their counterparts in the U.S. and China. 

####  [Montezuma's Revenge can finally be laid to rest as Uber AI researchers crack the classic game](https://www.theregister.co.uk/2018/11/28/montezumas_revenge_beaten/)
**Katyanna Quach, The Register** | from [December 10th edition](/digests/the-fourteenth)

You probably don’t remember the 1984 Atari platformer *Montezuma's Revenge*, but the game’s difficulty continues to haunt AI researchers 38 years later. The game provides a fierce challenge for AI algorithms because of the delayed nature of its rewards, often requiring many intermediate steps before the play can advance. Last week, Uber announced that they’ve beaten the game using a new reinforcement learning algorithm called Go-Explore, which does not rely on the computationally expensive neural networks favored by DeepMind and OpenAI.

<hr>

## Concerns & Hype

#### [Why AI will not replace radiologists](https://towardsdatascience.com/why-ai-will-not-replace-radiologists-c7736f2c7d80)
**Dr. Hugh Harvery, Medium** | from [June 18th edition](/digests/the-second)

Popular press is abuzz with proclamations that AI will consume all human jobs starting with ones that involve labor and repetition; experts suggest this would create severe problems for people who cannot afford to transition out of those positions. In the medical field, AI experts praise the ability for machines to perform faster and better diagnostics than their human radiologist counterparts.  But will AI fully replace them? One doctor thinks otherwise.

#### [Emergency Braking Was Disabled When Self-Driving Uber Killed Woman, Report Says](https://www.nytimes.com/2018/05/24/technology/uber-autonomous-car-ntsb-investigation.html)
**Daisuke Wakabayashi, NYTimes** | from [June 18th edition](/digests/the-second)

This story camed out when the National Transportation Safety Board had released its initial report on the pedestrian fatality in Uber’s self-driving car program. Uber’s AI had a tendency to detect non-existent obstacles, so they disabled two emergency braking features. They also operated self-driving cars with only a single human safety driver, requiring that driver to simultaneously watch the road and monitor the self driving system. The incident illustrates the importance of redundant safety features in safety-critical AI systems.

####  ['The discourse is unhinged': how the media gets AI alarmingly wrong](https://www.theguardian.com/technology/2018/jul/25/ai-artificial-intelligence-social-media-bots-wrong)
**Oscar Schwartz, The Guardian** | from [July 30th edition](/digests/the-fifth)

Oscar Schwartz, a freelance writer and researcher with PhD for a thesis unconvering the history of machines that write literature, has written a nice summary of the current state of hype-infused AI coverage and the issues with it (a sentiment we here at Skynet Today can cleary get behind). He suggests journalists should be more cautious in their reporting and seek the aid of researchers, but also cautions incentives and popular culture make this a difficult problem to solve:

> While closer interaction between journalists and researchers would be a step in the right direction, Genevieve Bell, a professor of engineering and computer science at the Australian National University, says that stamping out hype in AI journalism is not possible. Bell explains that this is because articles about electronic brains or pernicious Facebook bots are less about technology and more about our cultural hopes and anxieties.

####  [Strategic Competition in an Era of Artificial Intelligence](https://www.cnas.org/publications/reports/strategic-competition-in-an-era-of-artificial-intelligence)
**Michael Horowitz, Elsa B. Kania, Gregory C. Allen and Paul Scharre, Center for a New American Security** | from [August 13th edition](/digests/the-sixth)

Andrew Ng received some flak for saying that AI is the “new electricity,” but the Center for a New American Security treats this idea seriously with a detailed exploration of past industrial revolutions. We are personally not totally sold on the idea, but it’s very much worth the read.

#### [UK cops run machine learning trials on live police operations. Unregulated. What could go wrong?](https://www.theregister.co.uk/2018/09/21/cops_use_of_machine_learning_is_a_minefield_of_poor_research_evidence_and_regulation/)
**Rebecca Hill, The Register** | from [September 24th edition](/digests/the-ninth)

 > "We need to be very careful that if these new technologies are put into day-to-day practices, they don’t create new gaming and target cultures,” 

The Royal United Services Institute (RUSI) a defense and security think tank published a [report](https://rusi.org/publication/whitehall-reports/machine-learning-algorithms-and-police-decision-making-legal-ethical) on the use of machine learning in police decision making. The report says that it is hard to predict the impact of ML-driven tools and algorithmic bias. It seems, however, that police in the UK continue to use these tools.

####  [In Advanced and Emerging Economies Alike, Worries About Job Automation](http://www.pewglobal.org/2018/09/13/in-advanced-and-emerging-economies-alike-worries-about-job-automation/)
**Richard Wike and Bruce Stokes, Pew Research Center** | from [October 10th edition](/digests/the-tenth)

This article reports the pessimistic results of a Pew opinion survey on the future impact of automation on the job market, conducted in 9 countries. In all countries, most people believe that in 50 years robots will do much of the work currently done by humans, while few believe that new jobs will be created by advances in automation (we would like to point out that this last opinion does not seem confirmed by historical data, as both factory machines and computers did create a substantial part of what we think as “modern jobs”).
People are also worried that automation will worsen inequalities, and do not believe that it will improve the economy.


####  [In the Age of A.I., Is Seeing Still Believing?](https://www.newyorker.com/magazine/2018/11/12/in-the-age-of-ai-is-seeing-still-believing)
**Joshua Rothman, The New Yorker** | from [November 19th edition](/digests/the-thirteenth)

Image forgery has a long history. Will algorithmically assisted fakes change anything to our media landscape? The New Yorker delivers a level-headed analysis of what will probably change, in good and in bad.

<hr>

## Analysis & Policy

#### [An Overview of National AI Strategies](https://medium.com/politics-ai/an-overview-of-national-ai-strategies-2a70ec6edfd)
**Tim Dutton, Medium** | from the [July 16th edition](/digests/the-fourth)

The race to become the leading country in AI is on. Russian president Vladimir Putin has said “Whoever becomes the leader in this (AI) sphere will become the ruler of the world”. Various countries have developed a national strategy for AI. Tim Dutton, an AI Policy researcher at CIFAR summarizes the key policies and goals of each national strategy. It makes for an interesting read to look at and compare the various perspectives of different countries regarding AI.


####  [Lethal Autonomous Weapons Pledge](https://futureoflife.org/lethal-autonomous-weapons-pledge/)
**Multiple authors, Future of Life Institute**  | from the [July 30th edition](/digests/the-fifth)

A large number of top AI researcher and institutions stating that 

>“Artificial intelligence (AI) is poised to play an increasing role in military systems. There is an urgent opportunity and necessity for citizens, policymakers, and leaders to distinguish between acceptable and unacceptable uses of AI. In this light, we the undersigned agree that the decision to take a human life should never be delegated to a machine.” 

and furthermore:

> “We, the undersigned, call upon governments and government leaders to create a future with strong international norms, regulations and laws against lethal autonomous weapons. These currently being absent, we opt to hold ourselves to a high standard: we will neither participate in nor support the development, manufacture, trade, or use of lethal autonomous weapons. We ask that technology companies and organizations, as well as leaders, policymakers, and other individuals, join us in this pledge.”

The pledge has already been signed by 223 organizations and 2852 individuals, with notable figures in AI such as DeepMind’s founders, Yoshua Bengio, and many more:

<figure>
  <img src="/content/digests/images/5/pledge.png" alt="AI weapons pledge"/>
  <figcaption>
    Credit: screenshot from pledge site
  </figcaption>
</figure>

####  [What Algorithmic Art can teach us about Artificial Intelligence](https://www.theverge.com/2018/8/21/17761424/ai-algorithm-art-machine-vision-perception-tom-white-treachery-imagenet)
**James Vincent, The Verge** | from the [August 27th edition](/digests/the-seventh)

Tom White, a lecturer in computational design at the University of Wellington in New Zealand, uses a “Perception Engine” to make abstract shapes that computer vision systems identify as objects from the ImageNet dataset. James Vincent from The Verge lookx at the ways in which White’s algorithmic art is being perceived by researchers, artists and the general public. 

####  [Defense Department pledges billions toward artificial intelligence research](https://www.washingtonpost.com/technology/2018/09/07/defense-department-pledges-billions-toward-artificial-intelligence-research/)
**Drew Harwell, Washington Post** | from the [September 10th edition](/digests/the-eigth)

DARPA has announced plans to invest $2 Billion towards various programs aiming to advance artificial intelligence. These programs will be in addition to the existing 20 plus programs dedicated to AI, and will focus on logistical, ethical, safety, privacy problems and explainable AI. This move will put the US at odds with Silicon Valley companies and academics who have been vocal about not developing AI for military use. 

> “This is a massive deal. It’s the first indication that the United States is addressing advanced AI technology with the scale and funding and seriousness that the issue demands,” said Gregory C. Allen, an adjunct fellow specializing in AI and robotics for the Center for a New American Security, a Washington think tank. “We’ve seen China willing to devote billions to this issue, and this is the first time the U.S. has done the same.”

####  [Women Breaking Barriers in A.I.](https://www.onlineeducation.com/women-breaking-barriers/artificial-intelligence)
**Jocelyn Blore, OnlineEducation.com** | from the [October 10th edition](/digests/the-tenth)

This article discusses current numbers, data-based conclusions and statistics about women in AI-related fields and ends up with case studies of tech institutions that successfully brought their ratios around 50% women or more. The systematic justification of every claim with backing studies and the final practical advice are particularly useful.

####  [Fed Scours Data for Signs of a Robot Takeover](https://www.bloomberg.com/news/articles/2018-10-30/fed-scours-data-for-signs-of-a-robot-takeover-eco-research-wrap)
**Jeanna Smialek, Bloomberg** | from the [November 5th edition](/digests/the-twelfth)

Despite worries about AI and automation leading to widespread unemployment being common, the precursor to that -- current workers becoming more productive and able to do more work aided by AI-powered tools -- has been curiously missing. The Fed has been looking into this, and has found that the effects of AI on productivity may be tricky to find in the numbers and may also take a while to be fully felt:

> “In the footnotes of his speech last week, Clarida cited “Artificial Intelligence and the Modern Productivity Paradox: A Clash of Expectations and Statistics,” a study by Massachusetts Institute of Technology economist Brynjolfsson and co-authors Daniel Rock and Chad Syverson. In it, the trio suggest that the “most impressive” capabilities of AI haven’t yet diffused widely.”

####  [Facial recognition technology: The need for public regulation and corporate responsibility](https://blogs.microsoft.com/on-the-issues/2018/07/13/facial-recognition-technology-the-need-for-public-regulation-and-corporate-responsibility/)
**Brad Smith, Microsoft Blog** | from [November 19th edition](/digests/the-thirteenth)

The article highlights how Artificial Intelligence has embedded in our professional and personal lives today and presents both negative and positive possible implications of it. One such technology is facial recognition which on one hand, could help locate a missing child and on the other, invade the privacy of millions of people by tracking them at all times. It discusses the role of government in regulating these technologies and the responsibility of the tech sector to put effort into mitigating bias and developing ethical products.

####  [The Impact of Artificial Intelligence on the World Economy](https://blogs.wsj.com/cio/2018/11/16/the-impact-of-artificial-intelligence-on-the-world-economy/)
**Irving Wladawsky-Berger, The Wall Street Journal** | from [November 19th edition](/digests/the-thirteenth)

> “Artificial intelligence has the potential to incrementally add 16 percent or around $13 trillion by 2030 to current global economic output-- an annual average contribution to productivity growth of about 1.2 percent between now and 2030, according to a September, 2018 report by the McKinsey Global Institute on the impact of AI on the world economy.”

A nice summary of recent projections about the worldwide economic impacts of AI over the next decade. The summary highlights key takeaways, the biggest of which are that AI will have a relatively large impact on the world economy but that it is also widen inequality among those with a starting lead and those who do not yet have much expertise in AI:

> “The economic impact of AI is likely to be large, comparing well with other general-purpose technologies in history,” notes the report in conclusion. “At the same time, there is a risk that a widening AI divide could open up between those who move quickly to embrace these technologies and those who do not adopt them, and between workers who have the skills that match demand in the AI era and those who don’t. The benefits of AI are likely to be distributed unequally, and if the development and deployment of these technologies are not handled effectively, inequality could deepen, fueling conflict within societies.”

<hr>

## Expert Opinions & Discussion within the field

#### [AI researchers allege that machine learning is alchemy](http://www.sciencemag.org/news/2018/05/ai-researchers-allege-machine-learning-alchemy)
**Science**, from [May 14th edition](/digests/the-first)

While the media and public discussion about AI is gearing up spiced with the occasional bitter criticism, it seems like the controversies don’t stop at the doors of AI researchers. A fervent internal discussion is happening at the same time about the scientific rigor and standards in the field as notable AI experts voice concerns about the quality of research being published. An article in Science featured part of this discussion, pointed to a talk given by Ali Rahimi, a Google AI researcher, who alleged that AI has become a form of ‘alchemy’. A couple of weeks ago, he and a few colleagues presented a paper on the topic at the International Conference on Learning Representations in Vancouver. The allegations - that researchers can’t tell why certain algorithms work and others don't, for example - have sparked much debate in the field. And a worthy debate it is - including substantial come-backs, e.g. by Yann LeCun, who pointed out AI is not alchemy, just Engineering, which is by definition messy. Check out the links for more information.

#### [AI researchers should help with some military work](https://www.nature.com/articles/d41586-018-05364-x)
**Gregory C. Allen, Nature**, from [June 18th edition](/digests/the-second) 

When news leaked that Google was working with the military to analyze drone footage using AI there was plenty of uproar, with thousands of employees signing a petition demanding Google to stop. Subsequently, Google released a set of principles for developing AI systems, outlining that they would not develop AI systems for the military. Greg Allen argues that such an all-or-nothing attitude towards working with the military is not only a security risk but could prevent progress in AI being used as a defensive measure. He proposes a more nuanced approach that will help the military use AI in ethical and moral ways.

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">I am pretty much in agreement with the nuanced article by Greg Allen of <a href="https://twitter.com/CNASdc?ref_src=twsrc%5Etfw">@CNASdc</a> about AI research and national security. <a href="https://t.co/hPg931Qe2O">https://t.co/hPg931Qe2O</a></p>&mdash; Andrew Moore (@awmcmu) <a href="https://twitter.com/awmcmu/status/1005218042807242752?ref_src=twsrc%5Etfw">June 8, 2018</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
</figure>

#### [What Happens if AI Doesn’t Live Up to the Hype?](https://www.bloomberg.com/news/articles/2018-06-18/what-happens-if-ai-doesn-t-live-up-to-the-hype)
> Jeremy Kahn, Bloomberg | from the [June 18th edition](/digests/the-third) 

Jeremy Kahn covers the increasing commentary in the artificial intelligence community on the limits of deep learning, including recent articles by Filip Piekniewski, Gary Marcus, and John Langford. On one hand, the critique of deep learning that it is unlikely to lead to artificial *general* intelligence doesn’t detract from its ability to solve many smaller problems. On the other hand, lofty unmet expectations could foretell disillusionment and future funding problems for the field.

####  [ Machine learning will be the engine of global growth](https://www.ft.com/content/133dc9c8-90ac-11e8-9609-3d3b945e78cf)
**Erik Brynjolfsson,  Financial Times** | from the [July 30th edition](/digests/the-fifth) 

Erik Brynjolfsson, a professor at MIT and co-author of ‘The Second Machine Age’, briefly summarizes the conclusions of research that predicts Machine Learning will lead to “not only higher productivity growth, but also more widely shared prosperity”.

> “In a [paper] (https://www.nber.org/chapters/c14007.pdf) with Daniel Rock and Chad Syverson, we discuss how machine learning is an example of a “general-purpose technology”. These are innovations so profound that they trigger cascades of complementary innovations, accelerating the march of progress and growth — for example, the steam engine and electricity. When a GPT comes along, past performance is no longer a good guide to the future.”

####  [Steps Toward Super Intelligence I, How We Got Here](https://rodneybrooks.com/forai-steps-toward-super-intelligence-i-how-we-got-here/)
**Rodney Brooks, Blog**  | from the [July 30th edition](/digests/the-fifth) 

Rodney Brooks writes a typically insightful look at past attempts at General AI and significant problems that require solving before General AI may be achieved.

> “Some things just take a long time, and require lots of new technology, lots of time for ideas to ferment, and lots of Einstein and Weiss level contributors along the way.”

> “I suspect that human level AI falls into this class. But that it is much more complex than detecting gravity waves, controlled fusion, or even chemistry, and that it will take hundreds of years.”

> “Being filled with hubris about how tech (and the Valley) can do whatever they put their mind to may just not be nearly enough.”

####  [ Q&A with Yoshua Bengio on building a research lab](https://www.cifar.ca/news/news/2018/08/01/q-a-with-yoshua-bengio)
**Graham Taylor, CIFAR**  | from the [August 13th edition](/digests/the-sixth) 

A nice retrospective on the career trajectory of Yoshua Bengio, with a lot of useful advice on how to progress well as a PhD candidate and a professor.

####  [Economics Nobel Prize Winner Sees No Singularity on the Horizon](https://spectrum.ieee.org/tech-talk/computing/hardware/abc-is-a-very-nice-alphabet)
**Philip E. Ross, IEEE Spectrum** | from the [October 22nd edition](/digests/the-eleventh) 

William Nordhaus, who won the Nobel Prize in economics this month, does not believe that the singularity is near. This brief article summarizes his argument: to the extent that a event like the singularity would be predictable, nothing indicates that it is about to happen.

####  [The compute and data moats are dead](https://smerity.com/articles/2018/limited_compute.html)
**Stephen Merity, smerity.com** | from the [November 5th edition](/digests/the-twelfth)

A great piece that discusses large compute and data being significant advantages in the long run in machine learning.

> “For machine learning, history has shown compute and data advantages rarely matter in the long run. The ongoing trends indicate this will only become more true over time than less. You can still contribute to this field with limited compute and even data. It is especially true that you can get almost all the advances of the field with limited compute and data. Those limits may even be to your advantage.”

####  [Artificial Intelligence Hits the Barrier of Meaning](https://www.nytimes.com/2018/11/05/opinion/artificial-intelligence-machine-learning.html)
**Melanie Mitchell, The New York Times** | from [November 19th edition](/digests/the-thirteenth)

In this opinion piece, Pr. Mitchell points out that despite recent advances in fields like image recognition or machine translation, researchers have not yet solved the issue of making algorithms that understand the task that they are solving: this is why machine translation regularly gives nonsensical results, and why many algorithms cannot deal with trivial modifications in the data they are processing.

>“The bareheaded man needed a hat” is transcribed by my phone’s speech-recognition program as “The bear headed man needed a hat.” Google Translate renders “I put the pig in the pen” into French as “Je mets le cochon dans le stylo” (mistranslating “pen” in the sense of a writing instrument).

<hr>

## Explainers

##### [NLP's ImageNet moment has arrived](https://thegradient.pub/nlp-imagenet/)
**Sebastian Ruder, The Gradient** | from the [July 16th edition](/digests/the-fourth) 

A nice summary of exciting recent NLP research for learning better representations. 

####  [The man who invented the self-driving car (in 1986)](https://www.politico.eu/article/delf-driving-car-born-1986-ernst-dickmanns-mercedes/)
**Janosch Delcker, Politico EU** | from the [July 30th edition](/digests/the-fifth) 

A nice summary on how “decades before Google, Tesla and Uber got into the self-driving car business, a team of German engineers led by a scientist named Ernst Dickmanns had developed a car that could navigate French commuter traffic on its own.“

####  [Yann LeCun: An AI Groundbreaker Takes Stock](https://www.forbes.com/sites/insights-intelai/2018/07/17/yann-lecun-an-ai-groundbreaker-takes-stock/)
**Insights Team, Forbes** | from the [July 30th edition](/digests/the-fifth) 

Forbes nicely summarized Yann LeCun’s 4 decades of significant contributions to the progress of AI and in particular neural net research.

####  [The Great AI Paradox](https://medium.com/mit-technology-review/the-great-ai-paradox-441da8f8747c#6d98)
**Brian Bergstein, MIT Technology Review** | from the [October 22nd edition](/digests/the-eleventh) 

This article is a level-headed summary of what machines currently can do, what they cannot do, and what risks are are more urgent than others.
> That second idea [we’d better hope that machines don’t eliminate us altogether], despite being an obsession of some very knowledgeable and thoughtful people, is based on huge assumptions. If anything, it’s a diversion from taking more responsibility for the effects of today’s level of automation and dealing with the concentration of power in the technology industry.

####  [Machine Translation. From the Cold War to Deep Learning](http://vas3k.com/blog/machine_translation/)
**Vasily Zubarev, vas3k blog** | from the [October 22nd edition](/digests/the-eleventh) 

A great explainer of Machine Translation covering its history and the progression to current state of the art.

####  [This quirky experiment highlights AI's biggest challenges](https://edition.cnn.com/2018/11/09/tech/janelle-shane-ai/index.html?utm_content=2018-11-09T21%3A00%3A06&utm_medium=social&utm_source=twbusiness&utm_term=image)
**Rachel Metz, CNN Business** | from [November 19th edition](/digests/the-thirteenth)

CNN Business interviewed Janelle Shane, a scientist who has been delighting the internet by sharing the strange outputs of her neural networks trained to reproduce data like ice cream flavors, cooking recipes and halloween costumes. The results make for a good crash course in neural networks’ limitations.

####  [Inside the world of AI that forges beautiful art and terrifying deepfakes](https://www.technologyreview.com/s/612501/inside-the-world-of-ai-that-forges-beautiful-art-and-terrifying-deepfakes/)
**Karen Hao, MIT Technology Review**

Another explainer on Generative Adversarial Networks. This articles includes good contextualisation and a simple but accurate explanation about how these networks work and discusses some recent applications.
 
<hr>

## Favourite Videos

<iframe width="560" height="315" src="https://www.youtube.com/embed/YY6LrQSxIbc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

<hr>

<iframe width="560" height="315" src="https://www.youtube.com/embed/yEOEqaEgu94" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

<hr>

<iframe width="560" height="315" src="https://www.youtube.com/embed/PCBTZh41Ris" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

<hr>

<iframe width="560" height="315" src="https://www.youtube.com/embed/_V-WpE8cmpc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

<hr>

<iframe width="560" height="315" src="https://www.youtube.com/embed/LqjP7O9SxOM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

<hr>

<iframe width="560" height="315" src="https://www.youtube.com/embed/NPEPx6VUgrg?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

## Favourite Tweets

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">&quot;The people who take Mr. Musk’s side are philosophers, social scientists, writers — not the researchers who are working on A.I., he [Oren Etzioni] said. Among A.I. scientists, the notion that we should start worrying about superintelligence is “very much a fringe argument.”&quot;<br><br>Yes <a href="https://t.co/RmBcZBWOOP">https://t.co/RmBcZBWOOP</a></p>&mdash; Skynet Today 🤖 (@skynet_today) <a href="https://twitter.com/skynet_today/status/1005912477350019072?ref_src=twsrc%5Etfw">June 10, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">I agree with <a href="https://twitter.com/math_rachel?ref_src=twsrc%5Etfw">@math_rachel</a> that tech companies and AI researchers who overhype their work are just as culpable as journalists for the AI Misinformation Epidemic.<br><br>Got AI expertise? Want to be part of the solution? Write for <a href="https://twitter.com/skynet_today?ref_src=twsrc%5Etfw">@skynet_today</a>! More info here: <a href="https://t.co/TzB3pVFVMO">https://t.co/TzB3pVFVMO</a> <a href="https://t.co/ErVTCuFBCe">https://t.co/ErVTCuFBCe</a></p>&mdash; Abigail See (@abigail_e_see) <a href="https://twitter.com/abigail_e_see/status/1022639248372105216?ref_src=twsrc%5Etfw">July 27, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">We need a Goldilocks Rule for AI: <br>- Too optimistic: Deep learning gives us a clear path to AGI!<br>- Too pessimistic: DL has limitations, thus here&#39;s the AI winter!<br>- Just right: DL can’t do everything, but will improve countless lives &amp; create massive economic growth.</p>&mdash; Andrew Ng (@AndrewYNg) <a href="https://twitter.com/AndrewYNg/status/1030554394557698049?ref_src=twsrc%5Etfw">August 17, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Me: Wait... <a href="https://twitter.com/elonmusk?ref_src=twsrc%5Etfw">@elonmusk</a> a global influencer in <a href="https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw">#AI</a> and <a href="https://twitter.com/hashtag/MachineLearning?src=hash&amp;ref_src=twsrc%5Etfw">#MachineLearning</a>?<br><br>Me: Oh...<br><br>Me: Really????<br><br>Me: Since when?<br><br>Me: Terminator pics, misleading headlines, <a href="https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw">#AI</a> dystopia, <a href="https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw">#AI</a> hype, and now this... :-/ <a href="https://t.co/kuRzj8aYXF">https://t.co/kuRzj8aYXF</a></p>&mdash; Dagmar Monett (@dmonett) <a href="https://twitter.com/dmonett/status/1038324510439731200?ref_src=twsrc%5Etfw">September 8, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">If there&#39;s one thing you could change about the media and public conversation on AI, what would it be? Here&#39;s mine: stop talking about AI as if it has agency, because it doesn&#39;t — it&#39;s the people building and deploying it who do.</p>&mdash; Arvind Narayanan (@random_walker) <a href="https://twitter.com/random_walker/status/1051584594519228427?ref_src=twsrc%5Etfw">October 14, 2018</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
</figure>

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Unit 365 of layer4 of a church progressive GAN draws trees. Unit 43 draws domes. Unit 14 draws grass. Unit 276 draws towers.<br><br>...and Unit 231 draws the eldritch abominations <a href="https://t.co/6mVMN7tfbm">pic.twitter.com/6mVMN7tfbm</a></p>&mdash; Janelle Shane (@JanelleCShane) <a href="https://twitter.com/JanelleCShane/status/1067953066131910656?ref_src=twsrc%5Etfw">November 29, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">You: &quot;AI powered deep fakes will herald a new era where we cannot tell what is true and false on the internet&quot;<br>Me: Drew used the power of &quot;right click&quot; to edit the headline on a piece of mine and I&#39;ve had people asking me if I know what &#39;hunger&#39; is for twelve hours <a href="https://t.co/GXClzog6eo">https://t.co/GXClzog6eo</a></p>&mdash; jongo dorts (@alexhern) <a href="https://twitter.com/alexhern/status/1062983322853429248?ref_src=twsrc%5Etfw">November 15, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

## Favorite memes

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="und" dir="ltr"><a href="https://t.co/hlpebKJryH">pic.twitter.com/hlpebKJryH</a></p>&mdash; James Bradbury (@jekbradbury) <a href="https://twitter.com/jekbradbury/status/1020413198296526848?ref_src=twsrc%5Etfw">July 20, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Name a more iconic trio, I&#39;ll wait. <a href="https://t.co/pGaLuUxQ3r">pic.twitter.com/pGaLuUxQ3r</a></p>&mdash; Vicki Boykis (@vboykis) <a href="https://twitter.com/vboykis/status/1032631145035427840?ref_src=twsrc%5Etfw">August 23, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">RL agorithms&#39; performance on Atari, ranked: <br><br>16. Evaluation <br>15. Conditions<br>14. Vary<br>13. Across<br>12. Papers<br>11. There&#39;s<br>10. No<br>9. Single<br>8. Metric<br>7. Picking<br>6. A<br>5. Single<br>4. Algorithm<br>3. Is<br>2. Misleading<br>1. Ape-X DQN</p>&mdash; Miles Brundage (@Miles_Brundage) <a href="https://twitter.com/Miles_Brundage/status/1035266957631778816?ref_src=twsrc%5Etfw">August 30, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">&quot;This paper looks amazing! I will definitely read it very soon.&quot; <a href="https://t.co/fLMaE35Oat">pic.twitter.com/fLMaE35Oat</a></p>&mdash; Michael Hendricks (@MHendr1cks) <a href="https://twitter.com/MHendr1cks/status/1047489699680583680?ref_src=twsrc%5Etfw">October 3, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">nEuRal nEtWOrKs ArE moDeLs of tHe BrAIn <a href="https://t.co/8cUP6lzBUf">pic.twitter.com/8cUP6lzBUf</a></p>&mdash; AI Memes for Artificially Intelligent Teens (@ai_memes) <a href="https://twitter.com/ai_memes/status/1053778708497158148?ref_src=twsrc%5Etfw">October 20, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Ladies, if he:<br><br>- requires lots of supervision<br>- yet always wants more power<br>- can&#39;t explain decisions<br>- optimizes for the average outcome<br>- dismisses problems as edge cases<br>- forgets things catastrophically<br><br>He&#39;s not your man, he&#39;s a deep neural network.</p>&mdash; Alex Champandard ✈️ #NeurIPS2018 (@alexjc) <a href="https://twitter.com/alexjc/status/1067773673636012037?ref_src=twsrc%5Etfw">November 28, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">It&#39;s time to stop <a href="https://t.co/alZjuINyDg">pic.twitter.com/alZjuINyDg</a></p>&mdash; AI Memes for Artificially Intelligent Teens (@ai_memes) <a href="https://twitter.com/ai_memes/status/1060579903060492288?ref_src=twsrc%5Etfw">November 8, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Ladies, if he:<br><br>- requires lots of supervision<br>- yet always wants more power<br>- can&#39;t explain decisions<br>- optimizes for the average outcome<br>- dismisses problems as edge cases<br>- forgets things catastrophically<br><br>He&#39;s not your man, he&#39;s a deep neural network.</p>&mdash; Alex Champandard ✈️ #NeurIPS2018 (@alexjc) <a href="https://twitter.com/alexjc/status/1067773673636012037?ref_src=twsrc%5Etfw">November 28, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

<hr>

That's all for this digest! If you are not subscribed and liked this, feel free to subscribe below!




