---
layout: post
title: "'Do You Trust This Computer’ Gets a Whole Lot Wrong About AI Risks"
excerpt: "A Chris Paine documentary about AI promoted by Elon Musk conflates real AI risks with imaginary ones"
author: aidan_rocke
editor: [andrey_kurenkov,limor_gultchin]
tags: [Elon Musk,singularity,AGI]
categories: [briefs]
redirect_from: /content/news/do-you-trust-elon
permalink: /briefs/do-you-trust
---

## What Happened

Chris Paine, who previously directed ["Revenge of the Electric Car"](https://en.wikipedia.org/wiki/Revenge_of_the_Electric_Car), recently produced a documentary on AI risks[^risks] titled ‘Do You Trust This Computer’.

<figure>
<iframe src="https://player.vimeo.com/video/262916153" width="640" height="360" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
<p><a href="https://vimeo.com/262916153">Do You Trust This Computer? Trailer</a> from <a href="https://vimeo.com">Vimeo</a>.</p>
</figure>

Prior to its release, it gained a large amount of attention when the space entrepreneur Elon Musk shared it with his 20+ million Twitter followers:

[^risks]: Present day real AI risks include technological unemployment, biased algorithms, unethical use of user data, algorithmic promotion of fake news, and military robots.

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">tweet.</p>&mdash; Elon Musk (@elonmusk) <a href="https://twitter.com/elonmusk/status/982119546420002817
">April 6, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

Besides sponsoring free online viewing of the documentary for several days and promoting the film on Twitter, Musk features in the documentary alongside Stuart Russell (co-author of Artificial Intelligence: A Modern Approach), Eric Horvitz (Director at Microsoft Research Labs), Andrew Ng (co-founder of Google Brain), Shivon Zilis (a Director of OpenAI), and a variety of AI entrepreneurs. Although the documentary covers a combination of both positive and negative possible impacts of AI, on the whole its message is very pessimistic; the main thesis is that the technology is quickly getting beyond our control and we should be very worried. The film actually opens with a quote from Mary Shelley’s Frankenstein:

> You are my creator, but I am your master…

In order to address these concerns, the documentary proposes the following solutions:
1. In the short term, AI must be regulated in order to manage its potential impact on the economy and autonomous weapons.
2. In the long term, humans must ‘merge with AI’ using a brain-computer interface of some kind in order to address the problem of controlling the next phase of development: super-intelligent AI.

Elon Musk, who co-founded Neuralink, a brain-computer interface company, explains further in the movie:

> I think it’s incredibly important that AI not be other, it must be us. And I could be wrong about what I’m saying, I’m certainly open to ideas if anybody can suggest a path that’s better. But I think we’re either going to have to either merge with AI or be left behind.

The current fascination with the topic of AI, as well as Elon Musk’s involvement in and promotion of the documentary, helped it gain much attention from both AI experts and non-experts, and reactions were decidedly different between the two groups.

## The Reactions

The AI research community, already tired of unrealistic coverage of recent AI progress, was seemingly unanimous in its disapproval. Many notable experts took to Twitter to voice their opinions on the film:

* Denny Britz, a former Google Brain researcher:

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">tweet</p>&mdash; Denny Britz(@dennybritz) <a href="https://twitter.com/dennybritz/status/983240441620410369
">April 6, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

* Miles Brundage, AI Policy Research Fellow at Oxford's Future of Humanity Institute:

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">tweet</p>&mdash; Miles Brundage(@Miles_Brundage) <a href="https://twitter.com/Miles_Brundage/status/982336109941178369?ref_src=twsrc%5Etfw">April 6, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

* Timnit Gebru, an AI researcher at Microsoft Research known for her work on AI ethics and algorithmic bias:

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">tweet.</p>&mdash; Timnit Gebru (@timnitGebru) <a href="https://twitter.com/timnitGebru/status/983924801621446659
">April 6, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

* François Chollet, an AI researcher at Google (and lead developer of the Keras framework):

<figure>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">twitter.</p>&mdash; François Chollet (@fchollet) <a href="https://twitter.com/fchollet/status/983059353488965632
">April 6, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>

In contrast, the coverage by journalists without expertise in AI was also critical but at times less willing to pass conclusive judgement:

* [Daniel Oberhaus, journalist at Motherboard](https://motherboard.vice.com/en_us/article/gymwem/do-you-trust-this-computer-ai-documentary):

>The breadth of the film sacrifices any chance of engaging with the question of artificial intelligence and its implications at anything deeper than the absolute surface level. The film mostly comes off as a montage of soundbites from leading AI researchers, who undoubtedly have profound insights to offer about AI, if only Paine had given them the space to do so in his film.

* [James Vincent, journalist at The Verge](https://www.theverge.com/2018/4/12/17229824/ai-documentary-superintelligence-elon-musk-do-you-trust-this-computer):

>It’s also notable that while much of this important work (on AI ethics and safety) is being done by women — people like Kate Crawford of the AI Now institute and Joy Buolamwini of the Algorithmic Justice League — the cast of talking heads in Do You Trust This Computer? is overwhelmingly male. Of the 26 experts featured in the film, 23 are men.

* [Noel Murray, of The Los Angeles Times](http://www.latimes.com/entertainment/movies/la-et-mn-capsule-do-you-trust-this-computer-review-20180405-story.html):

> Documentarian Chris Paine follows up "Who Killed the Electric Car?" and "Revenge of the Electric Car" with a movie far more skeptical about technological progress. "Do You Trust This Computer?" covers the major talking points about the benefits and dangers of artificial intelligence, assembling them into something engaging and alarming — if not exactly in-depth.

The contrast between AI experts' confident dissaproval with the media’s more mixed and often neutral evaluation reflects a problematic information-asymmetry and highlights the need for better public understanding of AI.

## Our Perspective

Although Chris Paine may have intended to inform people about the genuinely important topic of AI risks, his documentary does more harm than good by misinforming the audience in many egregious ways. Rather than objectively informing about the current state of the technology, the movie promotes an unrealistic belief that superhuman AI is imminent and seeks to evoke a sense of panic and anxiety about where we are headed.

The documentary misleads and creates panic primarily in three distinct ways:

1. **Omission and implication**: the documentary creates a sense of panic by introducing present-day AI risks without acknowledging the immense efforts to address them [^examples]. Granted, it is true that a lot more has to be done, but many have already stepped up to the challenge. Furthermore, key dialogues with Elon Musk, Stuart Russell and others imply drastic ideas that are not remotely true[^drastic] and easily debunked.

2. **Mixing fact with fiction**: worse yet, the documentary conflates real and fictional AI risks. Throughout the film, we are offered dystopian scenes from the Matrix, Terminator and Ex Machina, which are nowhere near real present day AI risks. The solutions it presents to these risks are also often very far from practical in the present day. The idea of ‘merging with AI’ is especially far from practical today and almost out of science fiction [^criticism].

3. **Manipulative emotional appeals**: the first 5 minutes, after opening with a quote from Frankenstein, feature a fast paced montage made up of foreboding music and short sound-bites which is clearly meant to evoke a sense of distrust and fear about AI. Similar cinematic
techniques are used all throughout the film to maintain this emotional influence [^cinematic].

[^drastic]: To list just a few: Elon Musk states that “A neural network is very close to how a simulation of the brain works”, another interviewee stating that “Deep Learning is totally different [from older AI techniques] - more like a toddler” (which is utterly false), a statement that “[Baxter](https://www.rethinkrobotics.com/baxter/) can do anything we can do with our hands" (again, utterly wrong), and even a direct implication that algorithms that Google is developing for very specific applications could take control of its data centers and do anything with all its data.

[^examples]: There are numerous unmentioned initiatives coming together to tackle many of the issues presented in the documentary, in fact too many to name them all, but here is a very partial attempt to acknowledge but a few: fake news is being addressed by various organisations and individuals, e.g.Factmata; the [General Data Protection Regulation (GDPR)](https://www.eugdpr.org/) is designed to protect European citizens from unfettered Capitalism in the age of Big Data and is an example of how responsible regulation can mitigate technological implications; there is also no mention of the work of [Kate Crawford](https://twitter.com/katecrawford), [Timnit Gebru](https://twitter.com/timnitGebru),[Arvind Narayan](https://twitter.com/random_walker) and many others on AI ethics and algorithmic bias.

[^criticism]: It is by far the most scientifically unsolved challenge Elon Musk has proposed to tackle, with immensely challenging problems of Digital Signal Processing, Brain-computer interfacing, Neuroscience, and AI itself. The interfacing of AI algorithms with human brains has never even been attempted, so it is currently entirely hypothetical. Moreover, it is strange to both posit that superintelligent AI may be malicious and propose we should go ahead and implant such AI in our brains.

[^cinematic]: All films and documentaries use these emotional devices, but this movie relies on them much more heavily than is normal. Last year’s documentary “AlphaGo” is a good example of a documentary that also uses cinematic techniques without being downright manipulative in their usage or distorting factual information.

It is because of the usage of these techniques that François Chollet was spot on in describing this film as **’gratuitous fear-mongering dressed up as a documentary’**. This egregious combination encourages viewers to form an incorrect understanding of real news concerning AI with the utterly false belief that AI is growing quickly beyond our control rather than just being developed by programmers much like other computer algorithms.


## TLDR

Chris Paine and his collaborators (Elon Musk notably among them) produced a documentary on AI which conflates real risks with imaginary ones. Considering that AI technology, like any technology, may be used for both good and evil it is essential to focus on the real issues of today and not be distracted by little understood science-fiction inspired ideas about the future.

<hr>
