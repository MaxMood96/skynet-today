---
layout: redirect
title: "Last Week in AI #323"
excerpt: "Anthropic‚Äôs Claude 4.5 goes agentic üß†üíª, GPT-5 claims pro-level chops üìä, California passes AI transparency law üèõÔ∏è, OpenAI drops Sora 2 video app üé¨üó£Ô∏è, Meta debuts Vibes AI video feed üì±‚ú®, and more!"
image: 
  feature: assets/img/digests/323/250930-sam-altman-sora-2-ew-157p-a4fcaa.jpg
  credit: <a href="<Image Source Link>"> <Author> / <Source Name> </a>
categories: [digests]
permalink: /digests/the-three-hundred-and-twenty-third
sidebartoc: true
redirect: https://lastweekin.ai/p/323
---### Top News

#### [Anthropic releases Claude Sonnet 4.5 in latest bid for AI agents and coding supremacy](https://www.theverge.com/ai-artificial-intelligence/787524/anthropic-releases-claude-sonnet-4-5-in-latest-bid-for-ai-agents-and-coding-supremacy)
![](https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/STKB364_CLAUDE_A.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200)

Anthropic announced Claude Sonnet 4.5, highlighting a major leap in autonomous ‚Äúcomputer use‚Äù and coding capabilities. In internal tests, the model ran unattended for 30 hours to build a Slack/Teams-like chat app, generating ~11,000 lines of code, up from Opus 4‚Äôs seven-hour autonomy earlier this year. Anthropic claims Sonnet 4.5 is its best model yet for real-world agents, coding, and general computer operation, with strong performance in cybersecurity, financial services, and research. Early testers like Canva report gains on complex, long-context workflows spanning codebase engineering, in-product features, and research.

Beyond the model itself, Anthropic is shipping agent-building infrastructure: access to virtual machines, memory, context management, and multi-agent support‚Äîthe same building blocks behind Claude Code. The company says Sonnet 4.5 is over 3x better at navigating browsers and using computers than last October‚Äôs system, informed by feedback from early-access customers (e.g., GitHub, Cursor). Product leads describe ‚Äúchief-of-staff‚Äù behaviors like cross-calendar scheduling, dashboard analysis with insight generation, and drafting status updates. Internally, Anthropic reports improved performance on continuous web search and candidate sourcing workflows, including generating spreadsheets of LinkedIn profiles, as the broader industry races to ship agentic features across consumer and enterprise use cases.

#### [OpenAI says GPT-5 stacks up to humans in a wide range of jobs](https://techcrunch.com/2025/09/25/openai-says-gpt-5-stacks-up-to-humans-in-a-wide-range-of-jobs/)
![](https://techcrunch.com/wp-content/uploads/2023/02/GettyImages-1065679054.jpg?resize=1200,849)

OpenAI introduced GDPval, a new benchmark evaluating AI against human professionals across nine high-GDP industries and 44 occupations, focused on producing research-style reports. In GDPval-v0, experienced professionals directly compared AI-generated deliverables with peer-produced ones and selected a winner, yielding a ‚Äúwin or tie‚Äù rate aggregated across occupations. GPT-5-high, a higher-compute variant of GPT-5, achieved 40.6% wins/ties versus industry experts, up from GPT-4o‚Äôs 13.7% roughly 15 months prior. Anthropic‚Äôs Claude Opus 4.1 scored 49%, which OpenAI attributes partly to visually pleasing graphics rather than substantive superiority, highlighting presentation effects in evaluator judgments.

The current test is narrow: it only measures report-quality outputs and not the broader, interactive, or operational tasks professionals actually perform. Covered industries include healthcare, finance, manufacturing, and government, with roles such as software engineers, nurses, journalists, and investment bankers (e.g., prompts included competitor landscape analyses for last‚Äëmile delivery). OpenAI‚Äôs team, including chief economist Aaron Chatterji and evaluations lead Tejal Patwardhan, views the results as evidence that workers can offload portions of their workload to models and that capabilities are improving rapidly. OpenAI plans more comprehensive, workflow-oriented and domain-expanded versions of GDPval to better assess real-world proficiency and determine when models truly surpass human experts.

#### [SB 53, the landmark AI transparency bill, is now law in California](https://www.theverge.com/ai-artificial-intelligence/787918/sb-53-the-landmark-ai-transparency-bill-is-now-law-in-california)
![](https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/25384193/STK470_AI_LAW_CVIRGINIA_C.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200)

California enacted SB 53, the Transparency in Frontier Artificial Intelligence Act, after Gov. Gavin Newsom signed it into law, replacing last year‚Äôs vetoed SB 1047. The new law focuses on transparency rather than prescriptive safety testing thresholds (like SB 1047‚Äôs $100M training-cost trigger). It requires ‚Äúlarge AI developers‚Äù to publicly publish a frontier AI safety and security framework on their websites, detailing how they incorporate national/international standards and industry-consensus best practices, and to post updates with reasoning within 30 days of any changes. It also establishes a channel to report ‚Äúpotential critical safety incidents‚Äù to California‚Äôs Office of Emergency Services, adds whistleblower protections for disclosures about significant health and safety risks from frontier models, and creates a civil penalty enforceable by the Attorney General. Annual update recommendations to the law will come from the California Department of Technology based on multistakeholder input and evolving international standards.

Key provisions that made it in include transparency of safety processes and whistleblower protections, while third-party evaluations were dropped. The bill‚Äôs emphasis on voluntary-like frameworks drew criticism as potentially light on enforceable obligations, though it does formalize reporting and penalties for noncompliance with disclosure requirements. AI companies split: Anthropic publicly endorsed SB 53 after negotiations; Meta launched a state-level super PAC to influence California AI policy; and OpenAI lobbied against the approach, arguing state rules should be harmonized with federal and global regimes. OpenAI suggested compliance ‚Äúsafe harbors‚Äù for developers who sign onto frameworks like the EU Code of Practice or enter safety agreements with U.S. federal agencies, seeking pathways to satisfy California requirements via parallel regulatory commitments.

#### [ChatGPT parent company OpenAI announces Sora 2 with AI video app](https://www.nbcnews.com/tech/tech-news/openai-announces-sora-2-ai-video-audio-app-rcna234753)
![](https://media-cldnry.s-nbcnews.com/image/upload/t_nbcnews-fp-1200-630,f_auto,q_auto:best/rockcms/2025-09/250930-sam-altman-sora-2-ew-157p-a4fcaa.jpg)

OpenAI announced Sora 2, a new video-and-audio generation model with improved photorealism, physics adherence, and native speech generation, alongside a new Sora iOS app for sharing and remixing AI videos. The model improves on Sora v1‚Äôs motion issues (e.g., realistic ball bounces) and demonstrated complex action scenes like gymnastics and skateboarding, though artifacts remain (e.g., a deforming staff in a koi pond scene). A new ‚Äúcameos‚Äù feature lets users insert verified likenesses into videos after a one-time video/audio identity capture; OpenAI says consent can be revoked. The app features an algorithmic feed with ‚Äústeerable ranking‚Äù to personalize content, and is invite-only at launch in the U.S. and Canada with ‚Äúgenerous limits‚Äù due to compute constraints, with optional paid extra generations planned if demand exceeds capacity.

On safety, OpenAI says all Sora outputs will include a visible watermark and industry-standard metadata; teen accounts get parental controls and time limits; and guardrails block unsafe content at creation by scanning prompts, multi-frame video, and audio transcripts for sexual content, terrorist propaganda, and self-harm. The company is expanding human moderation to review bullying and other harms. Notable technical additions include native speech generation and improved physical consistency, plus verified-likeness ‚Äúcameos‚Äù demonstrated publicly by an OpenAI researcher featuring himself and CEO Sam Altman. The Sora app focuses on social sharing/remixing, with access rolling out gradually; OpenAI positions Sora 2 as a step toward general-purpose video ‚Äúworld simulators‚Äù and more capable multimodal agents.

#### [Meta launches ‚ÄòVibes,‚Äô a short-form video feed of AI slop](https://techcrunch.com/2025/09/25/meta-launches-vibes-a-short-form-video-feed-of-ai-slop/)
![](https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-2152655802.jpg?resize=1200,802)

Meta launched Vibes, a short-form feed inside the Meta AI app and on meta.ai dedicated entirely to AI-generated videos, mimicking TikTok/Reels but with machine-made content. Users can browse clips from creators and regular users, with personalization kicking in over time via Meta‚Äôs recommendation algorithm. You can generate a video from scratch or remix any clip in-feed, then add visuals, layer music, tweak styles, and publish to Vibes or cross-post to Instagram and Facebook Stories/Reels. Early examples shown by Mark Zuckerberg include fuzzy creatures hopping between cubes, a cat kneading dough, and an ‚Äúancient Egyptian woman‚Äù taking a selfie‚Äîillustrating the surreal, synthetic aesthetic driving the feature.

Under the hood, the early version of Vibes uses partner models from Midjourney and Black Forest Labs while Meta builds out its own generative video/image models. The launch drew immediate user backlash in Instagram comments, calling the feature ‚ÄúAI slop,‚Äù especially as platforms grapple with floods of low-value AI content and YouTube moves to curb it. The push comes amid Meta‚Äôs broader AI reorgs: the creation of Meta Superintelligence Labs in June and a subsequent split of AI efforts into four groups focused on foundation models, research, product integration, and infrastructure. The move contrasts with Meta‚Äôs earlier guidance to prioritize ‚Äúauthentic storytelling‚Äù over ‚Äúunoriginal‚Äù short videos, making Vibes a notable pivot toward mass AI-generated media within its ecosystem.



### Other News
#### Tools
![](https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-29-at-2.55.40PM.png?resize=1200,683)

[OpenAI takes on Google, Amazon with new agentic shopping system](https://techcrunch.com/2025/09/29/openai-takes-on-google-amazon-with-new-agentic-shopping-system/). The feature lets U.S. ChatGPT users buy from Etsy (and soon over a million Shopify merchants) directly in chat via Apple Pay, Google Pay, Stripe, or card, while OpenAI open-sources the Agentic Commerce Protocol that could shift discovery and checkout power away from Google and Amazon.

[The Latest Gemini 2.5 Flash-Lite Preview is Now the Fastest Proprietary Model (External Tests) and 50% Fewer Output Tokens](https://www.marktechpost.com/2025/09/27/the-latest-gemini-2-5-flash-lite-preview-is-now-the-fastest-proprietary-model-external-tests-and-50-fewer-output-tokens/). The previews bring faster throughput (Flash-Lite hitting ~887 output tokens/s in external tests), better multi-pass reasoning and agent/tool use, and much lower verbosity‚Äîabout 50% fewer output tokens for Flash-Lite (‚âà24% for Flash)‚Äîwhich can cut latency and output-token costs.

[Microsoft just added AI agents to Word, Excel, and PowerPoint - how to use them](https://www.zdnet.com/article/microsoft-just-added-ai-agents-to-word-excel-and-powerpoint-how-to-use-them/). They let Copilot perform tasks like generating analyses, formulas, formatted documents, and fully formatted PowerPoint decks (including data visualizations, cross-file updates, and validation steps) from natural-language prompts, and are rolling out first on the web for Microsoft 365 Personal, Family and Copilot business subscribers through the Frontier program.

[Apple built its own ChatGPT-like app to test out new Siri AI revamp](https://mashable.com/article/apple-chatgpt-like-app-veritas-siri-ai-voice-assistant). Apple's internal "Veritas" chatbot is being used to test features for the Linwood system behind the Siri overhaul, including LLM-driven personal-data search and in-app AI tools, and is not intended for public release.

[OpenAI Is Preparing to Launch a Social App for AI-Generated Videos](https://www.wired.com/story/openai-launches-sora-2-tiktok-like-app/). The app lets users generate up to 10-second vertical AI videos with a TikTok-style feed, identity verification for likeness use and tagging, and no option to upload personal media.

[OpenAI launches ChatGPT Pulse to proactively write you morning briefs](https://techcrunch.com/2025/09/25/openai-launches-chatgpt-pulse-to-proactively-write-you-morning-briefs/). The feature generates five to ten personalized morning briefs (news roundups, agenda items and contextual recommendations) overnight for Pro subscribers, pulling from connected apps, previous chats and web sources while limiting daily output to avoid social-media‚Äëstyle engagement loops.

[OpenAI really, really wants you to start your day with ChatGPT Pulse](https://www.theverge.com/ai-artificial-intelligence/785881/openai-really-really-wants-you-to-start-your-day-with-chatgpt-pulse). It curates a daily set of proactive, personalized updates and action suggestions by accessing your chat history, calendar, email, and other connected apps (with your consent) to surface topical cards like schedule tips, meal or exercise plans, and quick research.

[Opera launches its AI-centric Neon browser](https://techcrunch.com/2025/09/30/opera-launches-its-ai-centric-neon-browser/). The subscription-based browser includes an AI chatbot, an agentic "Neon Do" that automates tasks using browsing context, repeatable prompt "Cards" for building mini-apps, code-snippet generation for visual reports, and workspace-style "Tasks" for organizing AI chats and tabs.

[Exclusive: Mira Murati‚Äôs Stealth AI Lab Launches Its First Product](https://www.wired.com/story/thinking-machines-lab-first-product-fine-tune/). The tool, called Tinker, automates fine-tuning of frontier open-source models like Meta‚Äôs Llama and Alibaba‚Äôs Qwen via supervised and reinforcement learning, letting users run downloaded custom models locally or elsewhere.

[Amazon links Nova Act, its AI agent creator, to VS Code, Cursor and Kiro ‚Äì GeekWire](https://www.geekwire.com/2025/amazon-links-nova-act-its-ai-agent-creator-to-visual-studio-code-cursor-and-kiro/). None

[Photoshop Has Added Google‚Äôs Viral Nano Banana AI Model to Generative Fill](https://petapixel.com/2025/09/26/photoshop-has-added-googles-viral-nano-banana-ai-model-to-generative-fill/). The models, available now in the Photoshop beta, let users pick Nano Banana or FLUX.1 (or Adobe‚Äôs Firefly) within Generative Fill to generate imagery optimized respectively for stylized, graphic elements or contextual accuracy before refining results with Photoshop‚Äôs layers and editing tools.

[DoorDash unveils Dot, its autonomous robot built to deliver your food](https://techcrunch.com/2025/09/30/doordash-unveils-dot-its-autonomous-robot-built-to-deliver-your-food/). DoorDash plans to deploy Dot, a compact, battery-swappable autonomous delivery vehicle tested in Phoenix that uses cameras, radar and lidar with onboard AI to carry up to 30 pounds of food at speeds up to 20 mph while operating on roads, bike lanes and sidewalks and supported by warehouses, charging stations and field operators.

#### Business
![](https://media.zenfs.com/en/reuters-finance.com/c4a0d550b8f19dd4691008f780de08aa)

[OpenAI generates $4.3 billion in revenue in first half of 2025, the Information reports (Sept 29)](https://finance.yahoo.com/news/openais-first-half-revenue-rises-043012507.html). It reported burning $2.5 billion in the period largely on R&D and operations for ChatGPT, held about $17.5 billion in cash and securities, and is targeting $13 billion in full-year revenue and $8.5 billion in cash burn.

[A look at OpenAI's tangled web of dealmaking](https://www.cnbc.com/2025/09/28/a-look-at-openais-tangled-web-of-dealmaking.html). It shows investors and analysts worrying that OpenAI's extensive, interlocking deals with partners like Nvidia, CoreWeave and Oracle ‚Äî plus massive infrastructure spending and financing arrangements ‚Äî may create unsustainable dependencies and financial risk unless the company and the broader AI industry can generate far larger revenues.

[OpenAI ropes in Samsung, SK Hynix to source memory chips for Stargate](https://techcrunch.com/2025/10/01/openai-ropes-in-samsung-sk-hynix-to-source-memory-chips-for-stargate/). The companies agreed to produce up to 900,000 high-bandwidth DRAM chips per month and collaborate on building AI-focused data centers in South Korea while integrating OpenAI tech into their operations.

[Meta Is Said to Acquire Chips Startup Rivos to Push AI Effort](https://www.bloomberg.com/news/articles/2025-09-30/meta-is-said-to-acquire-chips-startup-rivos-to-push-ai-effort). The startup builds its own GPUs, and Meta plans to use the acquisition to strengthen its in-house semiconductor development and reduce reliance on external suppliers like Nvidia.

[Meta strikes expanded $14.2B AI infrastructure deal with CoreWeave - SiliconANGLE](https://siliconangle.com/2025/09/30/meta-strikes-expanded-14-2b-ai-infrastructure-deal-coreweave/). None

[Microsoft embraces OpenAI rival Anthropic to improve Microsoft 365 apps](https://www.theverge.com/news/784392/microsoft-365-copilot-anthropic-ai-models-feature). The integration lets Microsoft 365 Copilot users opt into Anthropic‚Äôs Claude Sonnet 4 and Claude Opus 4.1 for Researcher and Copilot Studio, mix models from Anthropic, OpenAI, and others for specific tasks, and build agents powered by Claude while Anthropic continues to host its models on AWS.

[AI Startup Black Forest Labs Shoots for $4 Billion Valuation](https://www.pymnts.com/artificial-intelligence-2/2025/ai-startup-black-forest-labs-shoots-for-4-billion-valuation/). The company is reportedly seeking $200 million to $300 million in new funding to reach that valuation after earlier rounds had already pegged it at about $1 billion, and it develops image-generation models (some released under open-source licenses) and partners with peers like Mistral.

[AI Chip Startup Rebellions Gets Funds at $1.4 Billion Valuation](https://www.bloomberg.com/news/articles/2025-09-29/ai-chip-startup-rebellions-gets-funds-at-1-4-billion-valuation). The funding round, which included a $250 million Series C and strategic backing from Arm, will be used to mass-produce Rebellions‚Äô AI chips and accelerate product development for data center infrastructure.

[Former OpenAI and DeepMind researchers raise whopping $300M seed to automate science](https://techcrunch.com/2025/09/30/former-openai-and-deepmind-researchers-raise-whopping-300m-seed-to-automate-science/). The startup plans to build autonomous labs run by AI "scientists" and robots to run experiments, generate large amounts of physical-world data, and accelerate discovery of new materials like superconductors.

[Elon Musk‚Äôs xAI offers Grok to federal government for 42 cents](https://techcrunch.com/2025/09/25/elon-musks-xai-offers-grok-to-federal-government-for-42-cents/). The deal lets executive-branch federal agencies access Grok for 18 months at a unit price of $0.42, including xAI engineer support for integration.

[Elon Musk‚Äôs xAI accuses OpenAI of stealing trade secrets in new lawsuit](https://www.theguardian.com/technology/2025/sep/25/elon-musk-xai-openai-sam-altman-lawsuit). The filing alleges OpenAI systematically recruited former xAI staff, including engineers and a senior finance executive, to obtain xAI‚Äôs source code, data-center plans and other confidential information.

[Zoox chooses Washington, DC as its next autonomous vehicle testbed](https://techcrunch.com/2025/09/30/zooxs-next-autonomous-vehicle-testbed-is-washington-dc/). The company will begin by manually mapping DC streets with sensor-equipped Toyota Highlanders before rolling out limited tests with safety drivers this year as it works toward regulatory approvals and a future commercial robotaxi service.

[Dedicated mobile apps for vibe coding have so far failed to gain traction](https://techcrunch.com/2025/09/23/dedicated-mobile-apps-for-vibe-coding-have-so-far-failed-to-gain-traction/). But despite investor interest and growing desktop use, mobile vibe-coding apps have seen only minimal downloads and revenue so far, with most users sticking to desktop tools and many developers still needing to fix AI-generated code.

#### Research
![](http://www.marktechpost.com/wp-content/uploads/2025/09/blog-banner-95.png)

[Meta FAIR Released Code World Model (CWM): A 32-Billion-Parameter Open-Weights LLM, to Advance Research on Code Generation with World Models](https://www.marktechpost.com/2025/09/25/meta-fair-released-code-world-model-cwm-a-32-billion-parameter-open-weights-llm-to-advance-research-on-code-generation-with-world-models/). It was mid‚Äëtrained on ~3M execution and agent‚Äìenvironment trajectories (Python interpreter traces and ForagerAgent edits across ~10k executable repo images) to teach execution‚Äëlevel semantics and supports a 131k‚Äëtoken context, instruction/RL fine‚Äëtuning, and quantized inference on a single 80GB H100, with benchmarks showing competitive verified coding and math performance.

[SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?](https://arxiv.org/abs/2509.16941). It introduces a contamination-resistant, industrially focused benchmark with GPL and commercial code subsets, longer multi-file tasks, a human-in-the-loop verification workflow, and diagnostic analyses showing current LLM agents score much lower (‚â§23.3% public, ‚â§17.8% commercial) than on prior benchmarks.

[Reinforcement Learning on Pre-Training Data](https://arxiv.org/abs/2509.19249). The approach trains models via self-supervised reinforcement learning on unlabeled pre-training text using a next-segment reasoning reward‚Äîcomposed of Autoregressive Segment Reasoning (ASR) and Middle Segment Reasoning (MSR) tasks evaluated by a generative reward model‚Äîto improve general and mathematical reasoning and scale with compute.

[The Era of Real-World Human Interaction: RL from User Conversations](https://arxiv.org/abs/2509.25137). It proposes RLHI, a method that learns from real user conversations by using user follow-ups to rewrite and pair model outputs and by training persona-conditioned reward models on long-term histories to improve personalization, instruction-following, and reasoning.

[Soft Tokens, Hard Truths](https://arxiv.org/abs/2509.19170). We introduce a continuous-token finetuning method that enables reinforcement-learning‚Äìfriendly soft and fuzzy chain-of-thought training without ground-truth traces, yielding similar pass@1, better pass@32 diversity, improved robustness, and entropy preservation compared with discrete CoT while allowing standard discrete inference on the trained models.

[What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT](https://arxiv.org/abs/2509.19284). Their analysis shows that shorter chains of thought with fewer review tokens‚Äîand especially a lower fraction of steps belonging to failed exploratory branches (Failed-Step Fraction)‚Äîpredict and causally improve accuracy across models and tasks, outperforming length- or review-based selection.

[Short window attention enables long-term memorization](https://arxiv.org/abs/2509.24552). Combining linear RNNs with sliding-window attention, the paper finds that shorter windows improve long-context retrieval, and introduces stochastic window-size training to balance long- and short-context performance.

[Evolution of Concepts in Language Model Pre-Training](https://arxiv.org/abs/2509.17196). Using crosscoders to align features across training checkpoints, the paper traces how human-interpretable linear features emerge, rotate, and fade during pre-training and links these microscopic dynamics to macroscopic task performance and a phase transition from statistical to feature learning.

[Hierarchical Retrieval: The Geometry and a Pretrain-Finetune Recipe](https://arxiv.org/abs/2509.16411). They prove asymmetric dual-encoder embeddings can represent and be learned to recover hidden DAG-style hierarchies for retrieval, identify a "lost-in-the-long-distance" failure mode at low embedding dimensions, and propose a pretrain-then-finetune on long-distance pairs to improve retrieval performance.

[ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory](https://arxiv.org/abs/2509.25140). It maintains a continually updated memory of distilled reasoning patterns from both successes and failures and uses memory-aware test-time scaling to guide exploration so agents learn from past experiences and improve over time.

[Discovered Policy Optimisation](https://arxiv.org/abs/2210.05639). Building on mirror learning, the paper presents a meta-learned drift function that yields a new Learnt Policy Optimisation approach and the Discovered Policy Optimisation algorithm, which attains state-of-the-art reinforcement learning performance.

[RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation](https://arxiv.org/abs/2509.16198). The system builds a structured, evolvable graph representation of requirements and design (the Repository Planning Graph) and uses it to drive proposal- and implementation-level planning, guided code generation, and test-driven validation to produce larger, more consistent software repositories than prior language-based planning methods.

[Advanced Financial Reasoning at Scale: A Comprehensive Evaluation of Large Language Models on CFA Level III](https://arxiv.org/abs/2507.02954). The study evaluates 23 LLMs on mock CFA Level III exams using multiple prompting strategies and human+LLM grading, finding frontier reasoning models can exceed the estimated pass threshold (with notable differences on essay questions), that chain-of-thought prompting boosts essay performance, grading by LLMs is systematically harsher than humans, and cost‚Äìlatency tradeoffs favor hybrid deployment strategies.

#### Concerns
![](https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195918462.jpg?w=1024)

[OpenAI rolls out safety routing system, parental controls on ChatGPT](https://techcrunch.com/2025/09/29/openai-rolls-out-safety-routing-system-parental-controls-on-chatgpt/). The new measures route emotionally sensitive chats to GPT-5 with ‚Äúsafe completions,‚Äù add parental controls for teen accounts (quiet hours, memory and image-generation limits, and harm detection), and will be iterated over a 120-day testing period amid mixed user reactions.

[Spotify‚Äôs Attempt to Fight AI Slop Falls on Its Face](https://futurism.com/future-society/spotify-admits-overrun-ai-slop). Spotify's new policies and detection efforts aim to curb AI-generated impersonations and spam, but a wave of fake tracks ‚Äî including a debunked Volcano Choir upload and million-stream AI "bands" like The Velvet Sundown ‚Äî shows enforcement and attribution remain inconsistent and technically difficult.

#### Analysis
![](https://hbr.org/resources/images/article_assets/2025/09/Sep25_22_AIslopmid.jpg)

[AI-Generated ‚ÄúWorkslop‚Äù Is Destroying Productivity](https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity). Employees are spending more time learning, adapting, and managing generative-AI tools than actually gaining efficiency, leaving companies with widespread adoption but little measurable productivity improvement.

<hr>

Copyright ¬© 2024 Skynet Today, All rights reserved.