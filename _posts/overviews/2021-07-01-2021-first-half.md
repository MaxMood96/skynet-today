---
layout: post
title: "AI News in First Half of 2021: a Digest"
excerpt: "An overview of the big AI-related stories of the first half of 2021"
image: 
  feature: assets/img/overviews/2021-07-01-2021-first-half/wordcloud.png
categories: [overviews]
tags: [overview,news]
permalink: /overviews/ai-news-2021-first-half
sidebartoc: true
highlight: true
---
## Overview

With 2021 quickly approaching its second half, we'd like to reflect on what's happened in AI during a year that began in the midst of the pandemic. Above is a wordcloud of the most common words used in titles of articles we've curated in our ['Last Week in AI' newsletter](https://lastweekin.ai/) over this past year. This reflects just about 500 articles that we've included in the newsletter in 2021 so far:

<figure>
 <img class="postimage_50" src="{{ site.imgpath }}/overviews/2021-07-01-2021-first-half/counts.png"/>
 <figcaption> Counts of terms in articles vs time</figcaption>
</figure>

Digging a bit deeper, we find that COVID 19 is no longer at the forefront of the news, with facial recognition, bias, and deepfakes being covered most:

<figure>
 <img class="postimage_75" src="{{ site.imgpath }}/overviews/2021-07-01-2021-first-half/topics.png"/>
 <figcaption> Counts of terms in article titles vs time</figcaption>
</figure>

Among institutions, Google still receives by far the most coverage:

<figure>
 <img class="postimage_75" src="{{ site.imgpath }}/overviews/2021-07-01-2021-first-half/institutions.png"/>
 <figcaption> Counts of terms in article titles vs time</figcaption>
</figure>

But enough overview -- let's go through the most significant articles we've curated from the past year, month by month. 

As in with our newsletter, these articles will be about Advances & Business, Concerns & Hype, Analysis & Policy, and in some cases Expert Opinions & Discussion within the field. 
They will be presented in chronological order, and represent a curated selection that we believe are particularly noteworthy. 
Click on the name of the month for the full newsletter release that started out that month.

## [January](https://lastweekin.ai/p/97)

<figure>
 <img class="postimage_50" src="{{ site.imgpath }}/digests/97/main.jpg"/>
 <figcaption><a href="https://thehill.com/policy/technology/531350-new-york-suspends-facial-recognition-use-in-schools"> Chris Mills Rodrigo / Getty Images via The Hill </a></figcaption>
</figure>

A big topic carried over from last year is the explosion of facial recognition software and the growing public pushback they are receiving, and January started off with new lawsuits and regulations on their uses.
Separately, OpenAI publicized a new impressive work called CLIP that is able to generate pictures from language prompts.

* [New York suspends facial recognition use in schools](https://thehill.com/policy/technology/531350-new-york-suspends-facial-recognition-use-in-schools)
* [A Black man spent 10 days in jail after he was misidentified by facial recognition, a new lawsuit claims](https://www.businessinsider.com/black-man-facial-recognition-technology-crime-2020-12)
* [This avocado armchair could be the future of AI](https://www.technologyreview.com/2021/01/05/1015754/avocado-armchair-future-ai-openai-deep-learning-nlp-gpt3-computer-vision-common-sense/)
* [Why we must democratize AI to invest in human prosperity, with Frank Pasquale](https://pando.com/2021/01/05/why-we-must-democratize-AI-invest-human-prosperity-with-Frank-Pasquale/)
* [Use of Clearview AI facial recognition tech spiked as law enforcement seeks to identify Capitol mob](https://www.theverge.com/2021/1/10/22223349/clearview-ai-facial-recognition-law-enforcement-capitol-rioters)
* [National AI Initiative Office launched by White House](https://www.fedscoop.com/national-ai-initiative-office-launched/)

## [February](https://lastweekin.ai/p/101)

<figure>
 <img class="postimage_50" src="{{ site.imgpath }}/digests/101/main.jpg"/>
 <figcaption><a href="https://www.fastcompany.com/90596320/amnesty-international-crowdsourced-facial-recognition-map"> Benedikt Geyer and Michael Daniels / Unsplash </a></figcaption>
</figure>

Another thread carried over from last year is the turmoil at Google's Ethical AI team. 
Following the firing of researcher Timnit Gebru, Google fired Margaret Mitchell, leading to more controversy in the press.
Again on the topic of facial recognition, a crowdsourced map was produced by Amnesty International to expose where these cameras might be watching. An OECD task force led by former OpenAI policy director Jack Clark was formed to calculate compute needs for national governments in an effort to craft better-informed AI policy. 

* [These crowdsourced maps will show exactly where surveillance cameras are watching](https://www.fastcompany.com/90596320/amnesty-international-crowdsourced-facial-recognition-map)
* [Why the OECD wants to calculate the AI compute needs of national governments](https://venturebeat.com/2021/01/26/why-the-oecd-wants-to-calculate-the-ai-compute-needs-of-national-governments/)
* [Deepfake porn is ruining women’s lives. Now the law may finally ban it](https://www.technologyreview.com/2021/02/12/1018222/deepfake-revenge-porn-coming-ban/)
* [Band of AI startups launch ‘rebel alliance’ for interoperability](https://venturebeat.com/2021/02/24/band-of-ai-startups-launch-rebel-alliance-for-interoperability/)
* [Google fires researcher Margaret Mitchell amid chaos in AI division](https://www.cnet.com/news/google-fires-researcher-margaret-mitchell-amid-chaos-in-ai-division/)

## [March](https://lastweekin.ai/p/106)

<figure>
 <img class="postimage_50" src="{{ site.imgpath }}/digests/106/AC9B3CF7-B897-40F1-B212E922D73A556E_source.jpg"/>
 <figcaption><a href="https://www.scientificamerican.com/article/ai-system-can-sniff-out-disease-as-well-as-dogs-do/"> Leon Neal / Getty Images via Scientific American </a></figcaption>
</figure>

The AI Index report released in March paints an optimistic outlook on the future of AI development - we are seeing significant increases in private AI R&D, especially in the healthcare. Simultaneously, concerns about AI continue to manifest. Karen Hao of the _MIT Technology Review_ interviewed an important player in Facebook's AI Ethics group, and found that Facebook was over-focusing on AI bias at the expense of grappling with the more destructive features of its AI systems. In another development stemming from Google's Ethical AI fallout, a researcher publicly rejected a grant from the behemoth. 

* [The 2021 AI Index: Major Growth Despite the Pandemic](https://hai.stanford.edu/blog/2021-ai-index-major-growth-despite-pandemic)
* [Clearview AI sued in California by immigrant rights groups, activists](https://www.cnn.com/2021/03/09/tech/clearview-ai-mijente-lawsuit/index.html)
* [How Facebook got addicted to spreading misinformation](https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/)
* [Underpaid Workers Are Being Forced to Train Biased AI on Mechanical Turk](https://www.vice.com/en/article/88apnv/underpaid-workers-are-being-forced-to-train-biased-ai-on-mechanical-turk)
* [A researcher turned down a $60k grant from Google because it ousted 2 top AI ethics leaders: 'I don't think this is going to blow over'](https://www.businessinsider.com/ai-researcher-rejects-google-grant-fired-timnit-gebru-margaret-mitchell-2021-3)

## [April](https://lastweekin.ai/p/110)

<figure>
 <img class="postimage_50" src="{{ site.imgpath }}/digests/110/BOSTONDYNAMICS_STRETCH_CONTAINER_Credit_to_Boston_Dynamics.webp"/>
 <figcaption><a href="https://www.theverge.com/2021/3/29/22349978/boston-dynamics-stretch-robot-warehouse-logistics"> Boston Dynamics via The Verge </a></figcaption>
</figure>

Another report release in April, the Analysis on U.S. AI Workforce, shows how AI workers grew 4x as fast as all U.S. occupations.
In this month we also saw more reports of EU's growing regulations on AI commercial applications in high-risk areas.
This is an important legislative framework that may be borrowed by other governments in thef future.

* [Boston Dynamics unveils Stretch: a new robot designed to move boxes in warehouses](https://www.theverge.com/2021/3/29/22349978/boston-dynamics-stretch-robot-warehouse-logistics)
* [Forget Boston Dynamics. This robot taught itself to walk](https://www.technologyreview.com/2021/04/08/1022176/boston-dynamics-cassie-robot-walk-reinforcement-learning-ai/)
* [Analysis on U.S. AI Workforce](https://cset.georgetown.edu/research/u-s-ai-workforce/)
* [Google is poisoning its reputation with AI researchers](https://www.theverge.com/2021/4/13/22370158/google-ai-ethics-timnit-gebru-margaret-mitchell-firing-reputation)
* [Europe seeks to limit use of AI in society](https://www.bbc.com/news/technology-56745730)
* [EU is cracking down on AI, but leaves a loophole for mass surveillance](https://www.themandarin.com.au/154636-eu-is-cracking-down-on-ai-but-leaves-a-loophole-for-mass-surveillance/)

## [May](https://lastweekin.ai/p/114)

<figure>
 <img class="postimage_50" src="{{ site.imgpath }}/digests/114/main.webp"/>
 <figcaption><a href="https://www.theverge.com/2021/4/27/22403741/deepfake-geography-satellite-imagery-ai-generated-fakes-threat"> James Vincent / The Verge </a></figcaption>
</figure>

Late May saw Google announcing their new large language models that can significantly impact how search and other Google products work in the future.
This builds on top of the explosion of language model sizes over the last two years.
Perhaps this drive to commercialize large lanugage models is behind the firing of its Ethical AI team leads months before, who at the time were focused on characterizing the potential harm of using such models.

* [Google and UC Berkeley Propose Green Strategies for Large Neural Network Training](https://syncedreview.com/2021/04/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-5/)
* [How to stop AI from recognizing your face in selfies](https://www.technologyreview.com/2021/05/05/1024613/stop-ai-recognizing-your-face-selfies-machine-learning-facial-recognition-clearview/)
* [Making AI algorithms show their work](https://www.sciencedaily.com/releases/2021/05/210513142451.htm)
* [Google Plans to Double AI Ethics Research Staff](https://www.wsj.com/articles/google-plans-to-double-ai-ethics-research-staff-11620749048)
* [Google's plan to make search more sentient](https://www.vox.com/22442624/google-mum-lamda-ai-search-artificial-intelligence)
* [Sharing learnings about our image cropping algorithm](https://blog.twitter.com/engineering/en_us/topics/insights/2021/sharing-learnings-about-our-image-cropping-algorithm.html)

## [June](https://lastweekin.ai/p/118)

<figure>
 <img class="postimage_50" src="{{ site.imgpath }}/digests/118/main.jpeg"/>
 <figcaption><a href="https://www.wired.com/story/ai-write-disinformation-dupe-human-readers/"> Caroline Brehman / Getty Images via WIRED </a></figcaption>
</figure>

A worrying report from the U.N. surfaced in June that describes the possibility of a drone making autonomous target and attack soldiers during last year's Libya conflicts.
The report remains to be independently verified, but proliferation of autonomous lethal weapons looms large as there are no global agreements that limit their use.
Also as a sign of things to come, June also saw King County banning government use of facial recognition technology, the first of such regulations in the U.S.

* [The age of killer robots may have already begun](https://www.axios.com/age-killer-robots-begun-8e8813d9-0fa1-4529-baf9-3358c1703bee.html)
* [King County is first in the country to ban facial recognition software](https://komonews.com/news/local/king-county-is-first-in-the-country-to-ban-facial-recognition-software)
* [AI still sucks at moderating hate speech](https://www.technologyreview.com/2021/06/04/1025742/ai-hate-speech-moderation/)
* [Google is using AI to design its next generation of AI chips more quickly than humans can](https://www.theverge.com/2021/6/10/22527476/google-machine-learning-chip-design-tpu-floorplanning)
* [The False Comfort of Human Oversight as an Antidote to A.I. Harm](https://slate.com/technology/2021/06/human-oversight-artificial-intelligence-laws.html)
* [DeepMind scientist calls for ethical AI as Google faces ongoing backlash](https://venturebeat.com/2021/06/22/deepmind-scientist-calls-for-ethical-ai-as-google-faces-ongoing-backlash/)
* [LinkedIn’s job-matching AI was biased. The company’s solution? More AI.](https://www.technologyreview.com/2021/06/23/1026825/linkedin-ai-bias-ziprecruiter-monster-artificial-intelligence/)

## Conclusion

If you've enjoyed this piece, subscribe to our ['Last Week in AI' newsletter](https://lastweekin.ai/)!

Also, check out our weekly podcast covering these stories!
[Website](https://aitalk.podbean.com) \|
[RSS](https://feed.podbean.com/aitalk/feed.xml) \| 
[iTunes](https://podcasts.apple.com/us/podcast/lets-talk-ai/id1502782720) \|
[Spotify](https://open.spotify.com/show/17HiNdxcoKJLLNibIAyUch) \| 
[YouTube](https://www.youtube.com/channel/UCKARTq-t5SPMzwtft8FWwnA)
<iframe title="Let's Talk AI" id="multi_iframe" class="podcast_embed"
 src="https://www.podbean.com/media/player/multi?playlist=http%3A%2F%2Fplaylist.podbean.com%2F7703921%2Fplaylist_multi.xml&vjs=1&kdsowie31j4k1jlf913=4975ccdd28d39e38bf5a1ccaf0c6ca4337fa996b&size=430&skin=9&episode_list_bg=%23ffffff&bg_left=%23000000&bg_mid=%230c5056&bg_right=%232a1844&podcast_title_color=%23c4c4c4&episode_title_color=%23ffffff&auto=0&share=1&fonts=Helvetica&download=0&rtl=0&show_playlist_recent_number=10&pbad=1" 
 scrolling="yes" allowfullscreen="" width="100%" height="330" frameborder="0"></iframe>
